{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570ebcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yg\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\yg\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "import sys\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "try:\n",
    "    \n",
    "    \n",
    "    page=requests.get('https://insights.blackcoffer.com/ai-healthcare-revolution-ml-technology-algorithm-google-analytics-industrialrevolution/')\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    error_type, error_obj, error_info = sys.exc_info()\n",
    "    print('Error for link :',url)\n",
    "    print(error_type,'Line :',error_info.tb_lineno)\n",
    "    \n",
    "    \n",
    "time.sleep(2)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "links=soup.find_all('h1',attrs={'class':'entry-title'})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be08bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How AI will impact the future of work?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "170afc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI experts believe it’s going to be one of the main drivers of the fourth Industrial Revolution and that it has the potential to not just transform the tech sectors and going to open a new chapter of the society of the world that people try to understand themselves better rather than the outside world with AI because people who are naysayer and kind of try to drum up these doomsday scenarios are pretty irresponsible. After all, In the next, five to ten years AI is going to deliver so many improvements and the quality of our lives it is a renaissance, a golden age of machine- learning and artificial intelligence that was the realm of science fiction for the last several decades. AI is probably the most important thing humanities that have ever worked which is more profound than any work with technology, as it is important to harness the benefits and while minimizing the downside is focusing on autonomous systems like self-driving cars seen as the mother of all AI projects and has made applications like self-driving technology viable for the first time, three things happen at the same time number one data collection and data processing became easier because of better technologies right um you need data to fuel AI training and that’s been one of the big drivers the second thing that has happened is that computer processing has become faster that’s like the engine so no matter how much fuel you have if you don’t have that engine and processing the data on a timeframe that’s reasonable was just not possible and the third thing that’s happened is that new algorithms have been developed which has made AI much more powerful so #technology has been changing and developing at a pace that’s much faster than ever before and we have not been used to this rapid pace of change which means that we have not been used to thinking about how it’s going to impact our immediate future. The most important factor responsible for the growth of AI is Google and its AI what Google’s done is given all of us the power to get the relevant information we want at our fingertips this has created a shift in how things are bought but it didn’t happen overnight this started in 2004 but the major change only happens to start 2012 onwards Google’s taken away about 65% of sales people’s jobs that were primarily order takers and the ones that are remaining are likely to be gone over the next decade.\n",
      "\n",
      "In present several AI projects are helping in diagnosing diseases better match up drugs with people depending on what they’re sick they can get treated better so it’s going to help a whole lot of people get treated and get better #healthcare than would have had access to it before if you look at self-driving cars they’re going to be safer than people driving cars and the value that machine learning is providing is actually happening beneath the surface and it is things like improved search results improved product recommendations for customers improve forecasting for inventory management and literally hundreds of other things including speech-recognition or image-recognition that the performance levels are phenomenal  or drug discovery as these biological systems are very complicated because vaccines for TB and HIV developing that’s notably enabled by this rich data advanced in biology and machine learning and recent invention in which is an application we just launched for anybody with visual impairment ass it uses the latest cutting-edge computer vision technology to give anyone the ability to see, so anyone who has dyslexia can now use AI to be able to read better and with the  latest release of Windows 10 has this capability called IJ’s which enable the eye muscle that the gaze can help to type. Like the two sides of the coin, there are negative impacts of AI as well  Bill Gates Ellen Musk also tech giants in a way their views are pessimistic, to say the least, they warned against the potential of AI to replace humans in the workplace and Ella masks even went as far as to claim that AI is the biggest existential threat to mankind. because of the loss of a job, when you think about a job or a career choice if a majority of the tasks that comprise that career choice is likely to be these vulnerable tasks then that is a career at risk in the future so what are the tasks that AI will find? hard to do anything unpredictable anything that requires skills like creative thinking or empathy or interpersonal skills but it’s important to understand tomorrow whether Google is there or not, artificial intelligence is going to progress you know technology has just nature it’s that it’s going to evolve as  technology and in particular AI can, in fact, bring more empowerment more inclusiveness and at the same time it is important to be clear-eyed about displacement and unintended consequences like any other technology and work both skills so that people can find the jobs of the future create new jobs also the policy decisions that help people as they go through this change people already unhappy because of machine learning artificial intelligence as they think  if they’re not innovative enough or not creative enough your job will be taking away by a lot of machines AI for business going to affect the future of work specifically there are jobs that are at more risk of being taken over by AI and automation there is very wide dissonance on this, there are different reports that have been shared by  Oxford study that says 47% of US jobs are at risk of automation over the next few years meanwhile the general population and workers think differently a recent study conducted by college actually identifies that 97% of workers believe that most jobs will be automated but not their own this suggests that the general public needs to be educated on which jobs are  susceptible to this risk which are not and businesses need to be aware of the forthcoming skills gap of course not all jobs are equal the Oxford study that highlights this they examined 700 participants and found the generalist occupations that require creative knowledge or innovation are at least risk the same is true for occupations in education healthcare media and arts jobs on the flip side jobs like telemarketers junior lawyers accountants are at most risk in short there is a simple rule of thumb if your job is in some way predictable or routine the risk of automation is much higher if a job doesn’t require innovation or creativity then the return on investment for companies is higher on machines than real-time employees machines are faster can’t be distracted and can work 24/7 this is actually good for creative marketers because AI and automation can serve to augment their jobs rather than substituting them as impact of emerging technologies on the creative economy they stated that artificial intelligence is changing  creative content from beginning to end by 2030 AI will be able to write high school essays code in Python composed top 40s chart songs and make creative videos but all of these advancements also come with risks and costs take a look at this report by the global Commission on the future of work in the absence of effective transition policies many people will have to accept lower skilled and lower paying jobs high-skilled workers are taking less cognitively demanding jobs displacing less educated workers and this is already happening also technological dividends are being unevenly distributed among firms a very limited amount of companies tend to dominate when it comes to big data just think about Google and Facebook today they alone are responsible for 70% of the referral marketing traffic and  receive more than 50% of total global advertising budget so the question is in businesses workers and social institutions go into the same direction if companies and public policy leaders can understand the evolving landscape they can help the workforce anticipate the upcoming challenges technology and the demographic changes are leading to a smaller workforce compared to the previous generation and a workforce that has to pursue many careers during their time of work we need to provide workers with an environment where they can continuously upskill and grow governments will have to re-evaluate the educational system we will have to continuously learn and grow and companies will have to redesign their structure and their culture around technology just like during the Industrial Revolution we are heading into a new age and the great transformation that we’re about to see by 2022 it is estimated that 20 to 25 percent of the labor force will be displaced within 10 to 20 years however this is also an opportunity for people to get ahead for which different ways have to be find to attract and retain highly skilled workers and allow them the time to up skill themselves even during work hours and it is a  good way  to develop a learning community to benefit from each other and also to use technology to supplement goal tracking and  efforts instead of as a distraction in short what we are doing is  to bridge the dissonance and it is imperative to build a  map of how AI and automation will affect  industry and  company if this is an economic imperative how do people feel about committing itself to a lifelong approach to knowledge as  these risks are important but it is important to do things like from being upfront to have ethical charters like AI safety and to be very transparent and open and how we perceive progress there and figure out global frameworks by which we can engage just like Paris agreement and climate change by using  such forums bring people together as they engage on the hard questions and it will emerge answers and on the question of whether AI is a threat or not, artificial intelligence is not  a threat because there is a rare case where people need to be proactive in regulation instead of reactive because I think by the time we are reactive in AI regulation it’s too late right now we have machine learning algorithms that can solve an incredibly complex problem beyond any human intelligence  as they are mere machines that can be given enormous data set and they come up with brilliant correlations and insights but they’re not going threaten the human population anytime soon because fish intelligent isn’t terrible but human being a smart enough to learn that skills at least to have a complete toolbox to be prepared volatility of the future adaptability.\n",
      "Blackcoffer Insights 28: Mihir Bhatt, Delhi University ( SGTB KHALSA College)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links=soup.find_all('div',attrs={'class':'td-post-content tagdiv-type'})\n",
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3635139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive score: 101\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total positive score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '53.txt'\n",
    "positive_words_file = 'positive.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "418c0544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative score: 37\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='latin-1') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='latin-1') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total negative score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '53.txt'\n",
    "positive_words_file = 'negative-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f999b747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 1818\n"
     ]
    }
   ],
   "source": [
    "def count_total_words(dataset_file):\n",
    "   \n",
    "    with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    \n",
    "    words = content.split()\n",
    "\n",
    "    \n",
    "    total_words = len(words)\n",
    "\n",
    "    return total_words\n",
    "\n",
    "\n",
    "dataset_file = '53.txt'\n",
    "\n",
    "\n",
    "total_words = count_total_words(dataset_file)\n",
    "\n",
    "\n",
    "print(\"Total number of words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03596dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 198\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import re\n",
    "dataset_file = \"53.txt\"\n",
    "dictionary = pyphen.Pyphen(lang='en')\n",
    "def count_syllables(word):\n",
    "    return len(dictionary.inserted(word).split('-'))\n",
    "def count_complex_words(file):\n",
    "    complex_word_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', data)  \n",
    "\n",
    "        for word in words:\n",
    "            syllable_count = count_syllables(word)\n",
    "            if syllable_count > 2:\n",
    "                complex_word_count += 1\n",
    "\n",
    "    return complex_word_count\n",
    "complex_words_count = count_complex_words(dataset_file)\n",
    "print(\"Number of complex words:\", complex_words_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e36da70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 10\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def count_sentences(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', data)\n",
    "        sentence_count = len(sentences)\n",
    "\n",
    "    return sentence_count\n",
    "dataset_file = \"53.txt\"\n",
    "sentence_count = count_sentences(dataset_file)\n",
    "print(\"Number of sentences:\", sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e5293e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total number of characters: 8756\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_character_count(file):\n",
    "    total_character_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split() \n",
    "\n",
    "        for word in words:\n",
    "            total_character_count += len(word)\n",
    "\n",
    "    return total_character_count\n",
    "dataset_file = \"53.txt\"\n",
    "character_count = calculate_total_character_count(dataset_file)\n",
    "print(\"Sum of total number of characters:\", character_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21bab64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words present in data set: 1049\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total stop words present in data set:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '53.txt'\n",
    "positive_words_file = 'all-stop-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c29ae253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the dataset file: 2822\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    exceptions = ['es', 'ed']\n",
    "    count = 0\n",
    "    prev_char_vowel = False\n",
    "\n",
    "    if word[-2:] in exceptions:\n",
    "        return count\n",
    "\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            if not prev_char_vowel:\n",
    "                count += 1\n",
    "            prev_char_vowel = True\n",
    "        else:\n",
    "            prev_char_vowel = False\n",
    "\n",
    "    return count\n",
    "\n",
    "def sum_syllables_in_file(file):\n",
    "    total_syllables = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_syllables += count_syllables(word)\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "dataset_file = \"53.txt\"\n",
    "total_syllables = sum_syllables_in_file(dataset_file)\n",
    "print(\"Total syllables in the dataset file:\", total_syllables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7854d860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of personal pronouns mentioned: 14\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_personal_pronouns(file):\n",
    "    pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b(?:{})\\b'.format('|'.join(pronouns)), data)\n",
    "\n",
    "        for word in words:\n",
    "           \n",
    "            if word.lower() != 'us':\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "dataset_file = \"53.txt\"\n",
    "pronoun_count = count_personal_pronouns(dataset_file)\n",
    "print(\"Number of personal pronouns mentioned:\", pronoun_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99450d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa9102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f09e717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
