{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c605954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yg\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\yg\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "import sys\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "try:\n",
    "    \n",
    "    \n",
    "    page=requests.get('https://insights.blackcoffer.com/big-data-analytics-in-healthcare/')\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    error_type, error_obj, error_info = sys.exc_info()\n",
    "    print('Error for link :',url)\n",
    "    print(error_type,'Line :',error_info.tb_lineno)\n",
    "    \n",
    "    \n",
    "time.sleep(2)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "links=soup.find_all('h1',attrs={'class':'entry-title'})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8a5d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big Data Analytics in Healthcare\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6601646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quality and affordable healthcare is a vision of all governments across the globe. The high cost of Medical service and lack of sufficient infrastructure is detrimental to this vision. In developed countries such as the U.S., reducing healthcare cost is an agenda point of all the politicians.  Even in India, affordable healthcare will be as important as “Roti, Kapda and Makan” in the near future. \n",
      "Technology can play a big role in reducing healthcare cost and making it more efficient. The vast quantity of data is available with Hospitals and insurance providers. Big data can play a big role in analyzing this data to produce actionable insight. Some of the benefits of using big data are as follows,\n",
      "Reduce Fraud and Waste: \n",
      "Fraud has a big\n",
      "impact on everyone. In fact, the National Healthcare Anti-Fraud Association\n",
      "estimates that fraud costs Americans at least $33 billion to $55 billion\n",
      "annually – that’s approximately 3-5% of the nation’s health care spending of\n",
      "$2.26 trillion. For example: Sometimes, providers or hospitals report\n",
      "procedures or services that were never provided. \n",
      "Big data analytics can help an insurance company to discover these frauds. Big data can use a huge amount of historical data to identify expected procedure or service for reported illness (identified using diagnosis code). If the expected procedure code doesn’t match with a billed procedure code, insurance companies can tag claim as a potential fraud claim. Once a claim is tagged as a fraud claim, the manual examiner needs to do additional verification to ensure that the claim is submitted by fraud provider.\n",
      "Sometimes, patients’ fake identity to get the benefit of insurance. Using big data, companies can match patients’ information with services he/she has taken. If services taken by the patient is very different from the past medical history of patients, analytics can tag claim as one of the susceptible fraud claims.\n",
      "Storing of data:\n",
      "Traditional health care providers find it difficult to store a vast amount of data. More ever, traditional database stores only structured data. Big data can solve storage issue by handling huge volume and variety of data. Having historical data of the patient can reduce healthcare drastically. \n",
      "Improving scheduling of appointments:\n",
      "It is very tough to get a Physician’s appointment in developed countries. One of my friends, senior director in a multinational bank, got an appointment for hip replacement surgery with a waiting period of six months. He was not able to sit and as a result, he didn’t drive or come to the office for six months. The waiting period can be drastically reduced if the hospital is able to forecast the number of patients likely to miss appointments. Based on historical data, hospitals can predict the number of no shows and can accordingly schedule appointments so as not to miss any slot because of no shows.\n",
      "Reducing overpayment and underpayment made to\n",
      "hospital:\n",
      "If a health insurance company pays an amount to hospital/provider that is greater than the contracted amount for service, payment is called an overpayment. Similarly, if payment made is lesser than the contracted amount for service, payment is called an underpayment. Overpayment or underpayment is a big headache for both insurance companies and patients. According to AHA data, private insurance companies have consistently overpaid hospitals for inpatient care for more than three decades. These overpayments have varied significantly over the years, but have grown dramatically in the past few years. \n",
      "Overpayment or underpayment can happen because of multiple reasons such as system glitch, a coding error. Using cognitive analysis, big data can predict the payment amount. If the predicted payment amount is significantly different than the actual payment amount, the system can identify possible overpayments or underpayments. \n",
      "Predictive treatment:\n",
      "Throughout the world, healthcare is based on diagnosing the presence of disease and subsequently treating the disease if present. Early diagnosis of the illness is a major challenge. Patients do go for diagnosis only when the symptom is evident.  It becomes challenging for the physician to treat illness once illness grows beyond a certain level.\n",
      "Predictive or preventive can help to identify if an individual will develop a disease. Different forms of health device such as iWatch can capture data and send to the hospital at regular interval of time. Using predictive analysis, the hospital can predict if a patient is likely to develop an illness. Early diagnosis of illness can help doctors to treat patients effectively and at a lower cost. \n",
      "Predictive treatment can reduce the number of days a patient needs to be admitted in the hospital. As inpatient treatment is costlier than outpatient treatment, doctors can discharge patients if he/she thinks that the condition of the patient is not serious. The hospital can monitor the patient remotely using medical sensors and can call the patient to the hospital when it is required. \n",
      "Big data plays a big role when a person suffers from multiple illnesses. As per Dr. Abhishek Rai, M.S. Ortho of K.E.M. Medical College Mumbai, “It becomes challenging to operate patients when he suffers from multiple illnesses. Many a number of times, physicians are not aware of all issues with patients as patients themselves are not aware of all illness”. As an example, it’s tough to operate on a person suffering from diabetes as blood doesn’t coat easily for a diabetic person.  If a physician doesn’t have historical data of a diabetic person, he/she may operate diabetic person wrongly. \n",
      "Another example where big data analytics can play a huge role in predicting disease is a genetic disease. If a person has breast cancer, her child is 15-20 percent likely to develop breast cancer. Using big data analytics, the system can identify patients likely to suffer from genetic disease and request patients to do timely screening. Genetic diseases can be screened in first, second- or third-degree relatives to reduce the morbidity and mortality.  \n",
      "Timely diagnostic reports:\n",
      "In India, it takes 2-3 days on an average to get an MRI scan. Delay is not because of lack of medical instruments but because of lack of qualified radiologists. This problem can be mitigated by integrating Medical imaging with big data. Integration of medical imaging with big data will ensure that radiologists get the report in a short span of time. Big data will help not only to reduce the turnaround time required to get reports but also to get better reports. Technology can convert image to graphs and charts making it easier for radiologists to read the report. \n",
      "As data works on the principle of abundance instead of scarcity. So, the more data we have, the better the outcomes can be obtained. Thus, Big Data technology is clearly the digital disruptor to revolutionize the healthcare sector by consolidating the data from disparate platforms to build a 360-degree view about the human body and help the healthcare provider to generate solutions to life-threatening problems and improved healthcare opportunities.\n",
      "Blackcoffer Insights 10 | Prakhar Kaushik and Vivek Rai, IIM Calcutta\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links=soup.find_all('div',attrs={'class':'td-post-content tagdiv-type'})\n",
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f59d096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive score: 29\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total positive score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '148.txt'\n",
    "positive_words_file = 'positive.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f7c0e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative score: 35\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='latin-1') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='latin-1') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total negative score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '148.txt'\n",
    "positive_words_file = 'negative-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cccad966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 1163\n"
     ]
    }
   ],
   "source": [
    "def count_total_words(dataset_file):\n",
    "   \n",
    "    with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    \n",
    "    words = content.split()\n",
    "\n",
    "    \n",
    "    total_words = len(words)\n",
    "\n",
    "    return total_words\n",
    "\n",
    "\n",
    "dataset_file = '148.txt'\n",
    "\n",
    "\n",
    "total_words = count_total_words(dataset_file)\n",
    "\n",
    "\n",
    "print(\"Total number of words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "622e37aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 182\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import re\n",
    "dataset_file = \"148.txt\"\n",
    "dictionary = pyphen.Pyphen(lang='en')\n",
    "def count_syllables(word):\n",
    "    return len(dictionary.inserted(word).split('-'))\n",
    "def count_complex_words(file):\n",
    "    complex_word_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', data)  \n",
    "\n",
    "        for word in words:\n",
    "            syllable_count = count_syllables(word)\n",
    "            if syllable_count > 2:\n",
    "                complex_word_count += 1\n",
    "\n",
    "    return complex_word_count\n",
    "complex_words_count = count_complex_words(dataset_file)\n",
    "print(\"Number of complex words:\", complex_words_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f39b9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def count_sentences(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', data)\n",
    "        sentence_count = len(sentences)\n",
    "\n",
    "    return sentence_count\n",
    "dataset_file = \"148.txt\"\n",
    "sentence_count = count_sentences(dataset_file)\n",
    "print(\"Number of sentences:\", sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc194016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total number of characters: 6078\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_character_count(file):\n",
    "    total_character_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split() \n",
    "\n",
    "        for word in words:\n",
    "            total_character_count += len(word)\n",
    "\n",
    "    return total_character_count\n",
    "dataset_file = \"148.txt\"\n",
    "character_count = calculate_total_character_count(dataset_file)\n",
    "print(\"Sum of total number of characters:\", character_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de124f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words present in data set: 487\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total stop words present in data set:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '148.txt'\n",
    "positive_words_file = 'all-stop-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86edd498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the dataset file: 1960\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    exceptions = ['es', 'ed']\n",
    "    count = 0\n",
    "    prev_char_vowel = False\n",
    "\n",
    "    if word[-2:] in exceptions:\n",
    "        return count\n",
    "\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            if not prev_char_vowel:\n",
    "                count += 1\n",
    "            prev_char_vowel = True\n",
    "        else:\n",
    "            prev_char_vowel = False\n",
    "\n",
    "    return count\n",
    "\n",
    "def sum_syllables_in_file(file):\n",
    "    total_syllables = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_syllables += count_syllables(word)\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "dataset_file = \"148.txt\"\n",
    "total_syllables = sum_syllables_in_file(dataset_file)\n",
    "print(\"Total syllables in the dataset file:\", total_syllables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b72d4a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of personal pronouns mentioned: 2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_personal_pronouns(file):\n",
    "    pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b(?:{})\\b'.format('|'.join(pronouns)), data)\n",
    "\n",
    "        for word in words:\n",
    "           \n",
    "            if word.lower() != 'us':\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "dataset_file = \"148.txt\"\n",
    "pronoun_count = count_personal_pronouns(dataset_file)\n",
    "print(\"Number of personal pronouns mentioned:\", pronoun_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8081735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f5326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4419b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
