{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc89cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yg\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\yg\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "import sys\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "try:\n",
    "    \n",
    "    \n",
    "    page=requests.get('https://insights.blackcoffer.com/blockchain-in-fintech/')\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    error_type, error_obj, error_info = sys.exc_info()\n",
    "    print('Error for link :',url)\n",
    "    print(error_type,'Line :',error_info.tb_lineno)\n",
    "    \n",
    "    \n",
    "time.sleep(2)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "links=soup.find_all('h1',attrs={'class':'entry-title'})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43f45ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blockchain in Fintech\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce608cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Disruption in Fintech – The Lightning Network\n",
      "\n",
      "\n",
      "Blockchain or the Distributed Ledger Technology has\n",
      "already been around for some time now. Cryptocurrencies like Bitcoin, based on\n",
      "the Blockchain technology, are making entry into the formal finance world and\n",
      "increasingly becoming a medium for exchange. Though there are many potential\n",
      "use cases for Cryptocurrencies and the Indian Government is very critical about\n",
      "implementing the technology in banking and finance, it still has a lot of\n",
      "issues to be resolved before we can commercially use it for transactions. \n",
      "Some of the most important drawbacks of\n",
      "Cryptocurrencies like Bitcoin right now are as below:\n",
      "Scalability:Bitcoin can have <7 transactions per second as compared to ~47,000 via payment network giants like VisaThere is a block limit of 1MB, which amounts to 8GBs per 10 min on a Bitcoin block (to match 47,000 transactions per second). This essentially means that home computers cannot process this currently and it has very limited use cases with transactions requiring devices having the high computational powerCentralization:High computation power requirement would limit the usage of the network to only those who can afford itThis will eventually lead to fewer validations for the Distributed Ledger, defeating the whole purpose of using Blockchain. (A distributed ledger means that everyone in the network can validate the transaction between two parties)\n",
      "So, it becomes important to have a cheaply available\n",
      "validation mechanism that can be carried out using a basic broadband connection\n",
      "in-home/small business computers. If two people have personal transaction\n",
      "history, it’s unimportant that it should be posted on the main blockchain every\n",
      "time a transaction takes place as it could bloat up the blockchain. Moreover,\n",
      "everyday transactions using cryptocurrency is not possible as the cost of\n",
      "posting a transaction for. Let’s say buying a coffee, can be more than the\n",
      "price of coffee itself.\n",
      "Introducing The Lightning Network:\n",
      "Lightning Network is the latest disruptive technology\n",
      "being researched currently in Fintech to make cryptocurrencies scalable. It\n",
      "basically adds\n",
      "an extra layer on top of the main Bitcoin Blockchain and enables payment\n",
      "channels between two parties over this layer. Micropayments for everyday\n",
      "transactions can be very easily carried out using this channel. Here is how it\n",
      "works:\n",
      "Suppose A buys a coffee\n",
      "from the nearby coffee shop B daily on her way to work. A and B decide to open\n",
      "a channel on the Blockchain for their everyday transactions. Once the channel\n",
      "(or the Lightning Network) is open, the two parties can keep a track of their\n",
      "daily transactions on this ledger. At the end of the month, with the ledger\n",
      "reflecting balances left with each party, they decide to close the channel.\n",
      "This final transaction is then recorded on the main Bitcoin Blockchain. This\n",
      "reduces the cost of the transaction and enables micropayments for everyday\n",
      "transactions.  Micropayment channels can defer updating the main\n",
      "blockchain with remaining balances at a later date. A large network of\n",
      "micropayments can be created as a secondary layer on top of the main blockchain\n",
      "to address the scalability issue and reduce transaction fees. Although this solution\n",
      "is very much in the initial stages, resolving the scalability issue and\n",
      "reducing transaction fees by taking the transaction out of the main blockchain\n",
      "will give a big boost to the use of Cryptocurrencies.\n",
      "How do payments take place on the lightning network?\n",
      "The two parties exchange a single key for validation\n",
      "of their spend transactions. They can conduct an unlimited number of transactions\n",
      "on this channel and finally when one party closes the channel, the balances\n",
      "will be added to the blockchain.\n",
      "Each\n",
      "user can open a digital wallet to store Bitcoins and deposit some coins in it\n",
      "once the channel is opened (this money is kind of a security deposit on behalf\n",
      "of both the parties to honor their transaction)Once\n",
      "they need to exchange money after their books are updated, they can sign off\n",
      "the ledger in the channelFinally,\n",
      "this will be added to the blockchain once the channel is closed\n",
      "The network is globally scalable since to reach any\n",
      "person through connected channels network, you just need to know the path to\n",
      "connect to that person through leveraging your existing network. Once the\n",
      "network develops in future, the requirement to open a separate channel too\n",
      "would cease to exist since the algorithm will automatically find the shortest\n",
      "route to connect to the person whom you want to pay based on the exhaustive\n",
      "peer to peer network. This would ease inter-country transactions and money can\n",
      "be sent across internationally within seconds.\n",
      "Limitations of the technology –\n",
      "Since the channel for Lightning Network is separate and not connected with the main Blockchain, it will not be backed by the security of the original Blockchain. This can be a major concern for its widespread adoption and the companies should research extensively into this. Another challenge is its dependency on the internet. The Lightning Network is not capable of storing coins digitally in a hardware wallet. This makes it prone to hackers since the wallet will be available online. Also, transferring large amounts of money is something that needs further detailed research, since bigger payment might struggle with routing in the network.\n",
      "Nevertheless, this technology is really fascinating and has a very broad usage through the implementation of Bitcoins and Distributed Ledger in everyday life. Once this is rolled out for customer experience, micropayments will be possible between two parties on Blockchain, just as we currently have wallets to transfer money for small purchases. The Lightning Network has a long way to go and is surely going to become the next big disruption in Fintech domain after Blockchain.\n",
      "Blackcoffer Insights 11 | Chirag Soni - IIM BANGALORE\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links=soup.find_all('div',attrs={'class':'td-post-content tagdiv-type'})\n",
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b53a5390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive score: 19\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total positive score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '145.txt'\n",
    "positive_words_file = 'positive.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad93e068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative score: 14\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='latin-1') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='latin-1') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total negative score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '145.txt'\n",
    "positive_words_file = 'negative-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63acdeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 949\n"
     ]
    }
   ],
   "source": [
    "def count_total_words(dataset_file):\n",
    "   \n",
    "    with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    \n",
    "    words = content.split()\n",
    "\n",
    "    \n",
    "    total_words = len(words)\n",
    "\n",
    "    return total_words\n",
    "\n",
    "\n",
    "dataset_file = '145.txt'\n",
    "\n",
    "\n",
    "total_words = count_total_words(dataset_file)\n",
    "\n",
    "\n",
    "print(\"Total number of words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43b0bf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 117\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import re\n",
    "dataset_file = \"145.txt\"\n",
    "dictionary = pyphen.Pyphen(lang='en')\n",
    "def count_syllables(word):\n",
    "    return len(dictionary.inserted(word).split('-'))\n",
    "def count_complex_words(file):\n",
    "    complex_word_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', data)  \n",
    "\n",
    "        for word in words:\n",
    "            syllable_count = count_syllables(word)\n",
    "            if syllable_count > 2:\n",
    "                complex_word_count += 1\n",
    "\n",
    "    return complex_word_count\n",
    "complex_words_count = count_complex_words(dataset_file)\n",
    "print(\"Number of complex words:\", complex_words_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a6021c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 37\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def count_sentences(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', data)\n",
    "        sentence_count = len(sentences)\n",
    "\n",
    "    return sentence_count\n",
    "dataset_file = \"145.txt\"\n",
    "sentence_count = count_sentences(dataset_file)\n",
    "print(\"Number of sentences:\", sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ecc4de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total number of characters: 4984\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_character_count(file):\n",
    "    total_character_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split() \n",
    "\n",
    "        for word in words:\n",
    "            total_character_count += len(word)\n",
    "\n",
    "    return total_character_count\n",
    "dataset_file = \"145.txt\"\n",
    "character_count = calculate_total_character_count(dataset_file)\n",
    "print(\"Sum of total number of characters:\", character_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bd07f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words present in data set: 663\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total stop words present in data set:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '130.txt'\n",
    "positive_words_file = 'all-stop-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e505d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the dataset file: 1483\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    exceptions = ['es', 'ed']\n",
    "    count = 0\n",
    "    prev_char_vowel = False\n",
    "\n",
    "    if word[-2:] in exceptions:\n",
    "        return count\n",
    "\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            if not prev_char_vowel:\n",
    "                count += 1\n",
    "            prev_char_vowel = True\n",
    "        else:\n",
    "            prev_char_vowel = False\n",
    "\n",
    "    return count\n",
    "\n",
    "def sum_syllables_in_file(file):\n",
    "    total_syllables = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_syllables += count_syllables(word)\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "dataset_file = \"145.txt\"\n",
    "total_syllables = sum_syllables_in_file(dataset_file)\n",
    "print(\"Total syllables in the dataset file:\", total_syllables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96715927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of personal pronouns mentioned: 2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_personal_pronouns(file):\n",
    "    pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b(?:{})\\b'.format('|'.join(pronouns)), data)\n",
    "\n",
    "        for word in words:\n",
    "           \n",
    "            if word.lower() != 'us':\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "dataset_file = \"145.txt\"\n",
    "pronoun_count = count_personal_pronouns(dataset_file)\n",
    "print(\"Number of personal pronouns mentioned:\", pronoun_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3404872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdcd9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f3544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
