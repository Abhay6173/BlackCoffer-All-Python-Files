{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f343b173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yg\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\yg\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "import sys\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "try:\n",
    "    \n",
    "    \n",
    "    page=requests.get('https://insights.blackcoffer.com/impact-of-covid-19-on-the-global-economy/')\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    error_type, error_obj, error_info = sys.exc_info()\n",
    "    print('Error for link :',url)\n",
    "    print(error_type,'Line :',error_info.tb_lineno)\n",
    "    \n",
    "    \n",
    "time.sleep(2)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "links=soup.find_all('h1',attrs={'class':'entry-title'})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679c4102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPACT OF COVID-19 ON THE GLOBAL ECONOMY\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea51bb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "It was 14th March and I was\n",
      "altogether prepared for my last theater competition of this very year. \n",
      "I only knew in my core how much this competition meant for me. In the morning I made some last-minute calls to my diligent team who were ceaselessly practicing for the past few days to confirm to me that they were all coming for the competition because of the alarming Coronavirus ball game going outside the market. It was not like I wasn’t aware of the situation but I believed that I would be able to handle it because there’s a quote in theatre that says, “Fear is only as deep as the mind allows” and to some length I was fearless. My passion, fondness, and attachment for the theatre were above all the notices and announcements that we’re rolling out.\n",
      "\n",
      "But then at once, I received a call from Mr. Sandeep, the head of the event who told me that the event is put off till the next few days and from that precise moment onwards the journey of hard and strenuous days began and it in point of fact felt like it was all meant to happen. The competition was postponed, the team was stuck in their homes grudgingly, time was haunting us all because of this Coronavirus. These were some of the cardinal ways in which this virus affected us but there was more to this sickness. This very sickness acted like a sadist. I was impressed as I found someone who could act better than me. It has reversed the ways we used to work, play and exercise and the world solution that was asked to practice by the professionals were Social Distancing. \n",
      "\n",
      "This virus was wild and dangerous towards the people who are in declining health conditions but obviously it could not take off his hands from the young people as well. The Coronavirus cases and deaths were heightening to a great extent. Also the major problem that came in the light was people being fully unprepared and this led to the public becoming snappier, intolerant and non-supportive needless to say as this virus was acting like a sadist. But by all means, our government knows how to best handle the affairs, they decided to shut down schools, colleges, bars anything that would involve the gathering of more than 10 people. With disinformation coming from all around related to this infection it becomes hard to judge for the audience what is true and what is false and it worsens when the public consumes this information by working from home. This virus was not only hollowing people from deep inside but was also supporting and increasing some other country-related issues one of which is Fake news which is a serious problem.\n",
      "With fake news traveling around the world, people come and start to blabber. People start offering numerous solutions and want that most of the people should follow it. They start acting like saints who know all the solutions to this pandemic. Some of the solutions are convenient to follow but some are not and are unhealthy which creates immense confusion and arguments. But the best way to stop the confusion and to avoid these people is to avoid their arguments and to not convince them with your points because it is rightly said a man convinced against his will is of the same opinions still. The thing to do is to look after your family and to avoid shady and deceitful people.\n",
      "But one thing that can’t be avoided is our expanding and maturing industries that lend a hand in developing our nation but no power to choose is left with our industries but to be at a standstill in this current moment as Coronavirus right now is winning the game. The untold number of industries is growing down and a major one is our Tourism industries and if this continues to happen then in no time there will be a loss to jobs close to more than 75 million. Many working people like in the tourism industry and not only in this peculiar industry but also in various others, people are getting suspended because of a hefty amount of lost revenue. One of my own family members resorted to this issue by working for free for the next few months in order to at least protect her job. Who should be blamed for these kinds of situations is also a point of concern for many people.\n",
      "“Massive hunger will definitely kill the poor before this virus”, this statement takes my immediate attention. What options are left with the daily-wage earners? I would say no option. They are the ones who are in the most condemning situations. Lockdown for us can be a way to relax or listen to karaoke, but lockdown for them means an end to their life. Unquestionably, this decision by our Prime Minister is the best he could take but when the best turns out to be the worst for someone then I think it’s a moment to question. Going to the internet and writing what’s the best way to spend this Quarantine, should definitely be what’s the best way in which we can help people, but naturally, this would not interest many people. Furthermore, this set off to become more hell when people start with the activity of stockpiling. Unnecessary piling of food is altogether a reason for shortage and ultimately hunger.\n",
      "\n",
      "My maid Mala who is a housewife and has a small suffering family, I believe could have written this article in a better manner if she would have the relevant education because she is the actual prey to this problem. She being the patient will exactly know the impact this virus can have on our lives because sitting in our homes with a cup coffee can never let us know what an empty cup feels like. Mala said to me think how much we would be tolerating that our Prime Minister apologized to the public for this Lockdown which was certainly a good thing for the masses. What all I could do to help her was to provide her family with some money and eatables. A small contribution with some motivation and a call once in 2 days I believe will not improve her state completely but would certainly provide her with the power to deal with it.  Not only Mala and her family, but there are also millions of people who are in the exact same condition. There are countless Mala in our country who are panicking, enduring and suffering each night with no food in their stomachs. Imagine an exact same situation for yourselves, it would without fail be the hardest situation. This is the impact a virus can create. For sure this article can be of endless pages owing to the fact that there are more stories to \n",
      "to this and each story is\n",
      "painful that the other.\n",
      "Labor Chowk in Noida has numerous stories of people conveying their problems and asking for help. This Chowk is in the main know for men looking for work. Quite a few men gather there each morning to get some work in order to feed their families with at least a roti but this virus even snatched that from their plates. A very known movie in our Indian cinemas is “Coolie” that says these laborers should get their pay till their sweat dries up. These people anyhow need money each day to feed their families but after these uncontrollable situations they at times are forced to eat filth and muck and this sickness might not kill these people but hunger and stained water definitely will. These stories will never end because it’s all meant to happen but I hope this situation does in order to provide some relief to them.\n",
      "\n",
      "Also how one would imagine that the movie “Six feet’s apart” would be acted in reality. The solutions related to this pandemic came swiftly and rapidly with the help and support of your doctors and nurses who all were serving us and the sufferers round-the-clock. Solutions like washing your hands for at least 20 seconds correctly, covering your mouth with a face mask and majorly avoiding unnecessary wandering on the streets and keeping yourself away from unhygienic people were asked to follow. The efforts of our doctors, nurses, government officials made me realize that my passion should not be above these notices and announcements but should move hand in hand with it. \n",
      "\n",
      "Right at this moment we all are moving with these circumstances and nobody knows what might happen in the future but one thing is of sure that nobody can ever forget this situation and indeed me as it had the ability to knock down my event that day. Many lessons were learned by all the world in these days some being that never ever take anything for granted because if that thing or that person leaves then life tends to become like a rock. Appreciate, admire and cherish whatever you have because you never know when it might leave you, ask from them who have just lost someone from this Corona Virus. Moments to live happily in this world are very few spend it with someone who makes you feel loved. Each day sun rises with a new hope to make a habit to feel the warmth and wish for a healthy life for yourself, your family and this world. Together we all are fighting this virus with unity.\n",
      "Blackcoffer Insights 16:-Tanishka Gupta, Institute of innovation in technology and management.\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links=soup.find_all('div',attrs={'class':'td-post-content tagdiv-type'})\n",
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b480fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive score: 43\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total positive score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '121.txt'\n",
    "positive_words_file = 'positive.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a37d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive score: 54\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='latin-1') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='latin-1') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total positive score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '121.txt'\n",
    "positive_words_file = 'negative-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4496a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 1612\n"
     ]
    }
   ],
   "source": [
    "def count_total_words(dataset_file):\n",
    "   \n",
    "    with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    \n",
    "    words = content.split()\n",
    "\n",
    "    \n",
    "    total_words = len(words)\n",
    "\n",
    "    return total_words\n",
    "\n",
    "\n",
    "dataset_file = '121.txt'\n",
    "\n",
    "\n",
    "total_words = count_total_words(dataset_file)\n",
    "\n",
    "\n",
    "print(\"Total number of words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce44254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 104\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import re\n",
    "dataset_file = \"121.txt\"\n",
    "dictionary = pyphen.Pyphen(lang='en')\n",
    "def count_syllables(word):\n",
    "    return len(dictionary.inserted(word).split('-'))\n",
    "def count_complex_words(file):\n",
    "    complex_word_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', data)  \n",
    "\n",
    "        for word in words:\n",
    "            syllable_count = count_syllables(word)\n",
    "            if syllable_count > 2:\n",
    "                complex_word_count += 1\n",
    "\n",
    "    return complex_word_count\n",
    "complex_words_count = count_complex_words(dataset_file)\n",
    "print(\"Number of complex words:\", complex_words_count)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8702bc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 65\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def count_sentences(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', data)\n",
    "        sentence_count = len(sentences)\n",
    "\n",
    "    return sentence_count\n",
    "dataset_file = \"121.txt\"\n",
    "sentence_count = count_sentences(dataset_file)\n",
    "print(\"Number of sentences:\", sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ff0c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total number of characters: 7346\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_character_count(file):\n",
    "    total_character_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split() \n",
    "\n",
    "        for word in words:\n",
    "            total_character_count += len(word)\n",
    "\n",
    "    return total_character_count\n",
    "dataset_file = \"121.txt\"\n",
    "character_count = calculate_total_character_count(dataset_file)\n",
    "print(\"Sum of total number of characters:\", character_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2008d0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words present in data set: 924\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total stop words present in data set:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '121.txt'\n",
    "positive_words_file = 'all-stop-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2af09ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the dataset file: 2301\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    exceptions = ['es', 'ed']\n",
    "    count = 0\n",
    "    prev_char_vowel = False\n",
    "\n",
    "    if word[-2:] in exceptions:\n",
    "        return count\n",
    "\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            if not prev_char_vowel:\n",
    "                count += 1\n",
    "            prev_char_vowel = True\n",
    "        else:\n",
    "            prev_char_vowel = False\n",
    "\n",
    "    return count\n",
    "\n",
    "def sum_syllables_in_file(file):\n",
    "    total_syllables = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_syllables += count_syllables(word)\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "dataset_file = \"121.txt\"\n",
    "total_syllables = sum_syllables_in_file(dataset_file)\n",
    "print(\"Total syllables in the dataset file:\", total_syllables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "177c4a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of personal pronouns mentioned: 29\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_personal_pronouns(file):\n",
    "    pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b(?:{})\\b'.format('|'.join(pronouns)), data)\n",
    "\n",
    "        for word in words:\n",
    "            \n",
    "            if word.lower() != 'us':\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "dataset_file = \"121.txt\"\n",
    "pronoun_count = count_personal_pronouns(dataset_file)\n",
    "print(\"Number of personal pronouns mentioned:\", pronoun_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b78b34d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 7346\n",
      "Total words: 1612\n",
      "Average word length: 4.557071960297767\n"
     ]
    }
   ],
   "source": [
    "def calculate_word_stats(file):\n",
    "    total_characters = 0\n",
    "    total_words = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_characters += len(word)\n",
    "            total_words += 1\n",
    "\n",
    "    return total_characters, total_words\n",
    "\n",
    "dataset_file = \"121.txt\"\n",
    "char_count, word_count = calculate_word_stats(dataset_file)\n",
    "average_word_length = char_count / word_count if word_count != 0 else 0\n",
    "\n",
    "print(\"Total characters:\", char_count)\n",
    "print(\"Total words:\", word_count)\n",
    "print(\"Average word length:\", average_word_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07acc09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81184a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdddc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158c9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
