{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb98fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yg\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\yg\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "import sys\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "try:\n",
    "    \n",
    "    \n",
    "    page=requests.get('https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/')\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    error_type, error_obj, error_info = sys.exc_info()\n",
    "    print('Error for link :',url)\n",
    "    print(error_type,'Line :',error_info.tb_lineno)\n",
    "    \n",
    "    \n",
    "time.sleep(2)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "links=soup.find_all('h1',attrs={'class':'entry-title'})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54413a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How Machines, AI, Automations, and Robo-human are Effective in Finance and Banking?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3ca9a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We all hear day in and day out that we amidst a technological revolution. But do we know what this really means?\n",
      "Before we understand how its going to impact us, let us first discuss what these terms really mean.\n",
      "A technological revolution simply means that we are in a period where better and newer technologies replace the others to get the job done faster and better. We are in an era with rapid innovations where machines are being compared to humans.\n",
      "\n",
      "Fig: Technological Revolution\n",
      "So, then what is Machine Learning?\n",
      "Machine Learning is basically the application of artificial intelligence into electronic systems to enable them to learn and enhance themselves without being programmed by humans. It is the evolution and development of computer programs that can access data and then use it to advance themselves. Whether you know it or not, you use machine learning-powered applications daily.\n",
      "Now, what is Artificial intelligence?\n",
      "At its simplest form, artificial intelligence is a field, which combines computer science and robust datasets, to enable problem-solving. \n",
      "In simple words, Artificial Intelligence is the technology that facilitates these machines to perform human like behaviour.\n",
      "Just like every other industry, machine learning is playing its role in the finance and banking industry too. In most cases where a human would perform the same task by performing the same calculations or following the same process can be taught to the machine which can now perform it by itself.\n",
      "Let us discuss a few examples of the applications that we might have come in our day to day running which are a result of machine learning in this industry:\n",
      "Portfolio ManagementRisk UnderwritingAlgorithmic TradingFraud DetectionProcess AutomationCustomer onboardingCustomer churnDecision MakingProcess Automation\n",
      "Portfolio Management\n",
      "In earlier days, an investor would need to consult a financial advisor to understand his/her risk appetite and advise accordingly. Today, using machine learning algorithms there exists the concept of a “Robo-Advisor” that requires any user to give certain inputs about their financial status and goals and calculates their risk tolerance and constructs and idle portfolio allocation for them. Young users today find this extremely useful rather than physically visiting an advisor and paying a fee for doing so.\n",
      "Risk Underwriting\n",
      "Underwriting is one of the core functions for most financial institutions especially banks and insurance companies where they are required to underwrite the risk of the customers before loaning out money or insurance policies. These underwriting activities are based on trends and thumb rules industrywide. The same has been introduced through machine learning which is able to underwrite risks today on a larger and more accurate scale.\n",
      "Algorithmic Trading\n",
      "Machine learning is a mathematical model that tracks market information, analyses massive data sources and study market conditions simultaneously to detect patterns which can be used for trading. This is humanly impossible to do in a fraction of time. Algorithmic systems can make millions of trades daily, often known as “high-frequency trading”. It is highly believed that deep learning is playing its role in calibrating real-time trading decisions.\n",
      "Fraud Detection\n",
      "With the increase in use and dependency on computers for financial transactions came the data security risk. There is an ample amount of valuable data stored online available to create potential risk. Machine learning thus helped in fraud detection by detecting anomalies in transactions and flagging them for scrutiny based on the risk factors defined by the institutions. Fraud identification in insurance claims, credit card payments, identity theft, account theft, are all areas in fraud detection that machine learning can help in.\n",
      "Process Automation\n",
      "Process automation is one of the most common applications of machine learning in finance. The technology has helped in replacing manual work, automate repetitive tasks to avoid redundancy, and as a result, increase productivity. Machine learning has benefitted these organizations to optimize costs, improve customer experiences, and scale up their services. Some examples of financial and banking firms using process automation are the use of chatbots, automated calls, paperwork automation, and gamified employee training.\n",
      "Customer onboarding\n",
      "In this highly competitive industry, customer acquisition and the customer onboarding process is highly relevant in building a good customer relationship. At any stage, during the onboarding, a slight inconvenience or delay can act as a barrier. Machine learning-enabled complete automation in this process for these financial and banking institutions. Today, from opening an account, filing for any application can be completed within a few minutes with utmost ease. With AI, customers’ behavioral patterns have been studied to improvise and make the whole process efficient and user-friendly.\n",
      "Customer churn\n",
      "With the multitude of offerings and availability of a plethora of options, customer stickiness is a big problem faced by financial firms. Customer churn forecasting is one of the best big data use cases. It helps in detecting customers who cancel their subscription and analyses the same to tailor products as per customer needs. Video streaming application, Netflix’s subscribers worldwide has continued to grow to reach 167 million through using machine learning analytics on their customer database.\n",
      "Decision Making\n",
      "Financial and banking institutions function on facilitating investments made by their customers. Organizations are constantly in search of customers from whom they can get more revenue. This is now possible through performing machine learning analysis on both structured and unstructured data which helps them make more informed decisions. It also analyses data from the website and mobile application to construct effective marketing campaigns for the targeted customers.\n",
      "Future of Machine Learning in Finance\n",
      "Financial monitoring, security analysis, prevention of money laundering, network security, investment predictions, personalization of customer service everything comes under the realm of the applications of machine learning in the financial and banking industry. Yet, this is just the tip of the iceberg, there is a lot more that is going to change in the future. It is now visibly imperative that while AI is beginning to create a wave of transformation across these industries and adapting to these changes s important for one’s survival. With smart technology applied everywhere, all financial firms are bound to turn into FinTech’s to stay relevant to the “silver tech generation” consisting of millennials and the GenZs.\n",
      "Final thoughts\n",
      "The financial services industry has entered the space of artificial intelligence and machine learning, and the pace is not surprising knowing the positive changes it has brought. Machine learning has the most use cases in finance than any other industry because of the available computer power and new machine learning tools. The greatest applications include simplifying customer engagement and accurate sales forecasting. It is only making this industry better and more efficient with each new adaptation. Machine learning algorithms have the capability to deal with a lot more than human capacity along with eliminating human error. As even the algorithms are constantly learning and innovating, they can serve as a bridge to a completely flawless automated financial system in the future. Nonetheless, the challenges of high cost and lack of resources that come along play a significant role in how early these firms can adopt these technologies. But even then, the future seems bright as the industry has enough adopters and prospects ready to explore.\n",
      "Blackcoffer Insights 28: Tanisha Gupta, XLRI\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links=soup.find_all('div',attrs={'class':'td-post-content tagdiv-type'})\n",
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb745d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive score: 39\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total positive score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '48.txt'\n",
    "positive_words_file = 'positive.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df1cffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative score: 15\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='latin-1') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='latin-1') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total negative score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '48.txt'\n",
    "positive_words_file = 'negative-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbde14dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 1203\n"
     ]
    }
   ],
   "source": [
    "def count_total_words(dataset_file):\n",
    "   \n",
    "    with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    \n",
    "    words = content.split()\n",
    "\n",
    "    \n",
    "    total_words = len(words)\n",
    "\n",
    "    return total_words\n",
    "\n",
    "\n",
    "dataset_file = '48.txt'\n",
    "\n",
    "\n",
    "total_words = count_total_words(dataset_file)\n",
    "\n",
    "\n",
    "print(\"Total number of words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "619d5acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 210\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import re\n",
    "dataset_file = \"48.txt\"\n",
    "dictionary = pyphen.Pyphen(lang='en')\n",
    "def count_syllables(word):\n",
    "    return len(dictionary.inserted(word).split('-'))\n",
    "def count_complex_words(file):\n",
    "    complex_word_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', data)  \n",
    "\n",
    "        for word in words:\n",
    "            syllable_count = count_syllables(word)\n",
    "            if syllable_count > 2:\n",
    "                complex_word_count += 1\n",
    "\n",
    "    return complex_word_count\n",
    "complex_words_count = count_complex_words(dataset_file)\n",
    "print(\"Number of complex words:\", complex_words_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9952069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 58\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def count_sentences(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', data)\n",
    "        sentence_count = len(sentences)\n",
    "\n",
    "    return sentence_count\n",
    "dataset_file = \"48.txt\"\n",
    "sentence_count = count_sentences(dataset_file)\n",
    "print(\"Number of sentences:\", sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30faf789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total number of characters: 6768\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_character_count(file):\n",
    "    total_character_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split() \n",
    "\n",
    "        for word in words:\n",
    "            total_character_count += len(word)\n",
    "\n",
    "    return total_character_count\n",
    "dataset_file = \"48.txt\"\n",
    "character_count = calculate_total_character_count(dataset_file)\n",
    "print(\"Sum of total number of characters:\", character_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d98efa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words present in data set: 529\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total stop words present in data set:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '48.txt'\n",
    "positive_words_file = 'all-stop-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28cdd386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the dataset file: 2145\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    exceptions = ['es', 'ed']\n",
    "    count = 0\n",
    "    prev_char_vowel = False\n",
    "\n",
    "    if word[-2:] in exceptions:\n",
    "        return count\n",
    "\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            if not prev_char_vowel:\n",
    "                count += 1\n",
    "            prev_char_vowel = True\n",
    "        else:\n",
    "            prev_char_vowel = False\n",
    "\n",
    "    return count\n",
    "\n",
    "def sum_syllables_in_file(file):\n",
    "    total_syllables = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_syllables += count_syllables(word)\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "dataset_file = \"48.txt\"\n",
    "total_syllables = sum_syllables_in_file(dataset_file)\n",
    "print(\"Total syllables in the dataset file:\", total_syllables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1d9456b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of personal pronouns mentioned: 5\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_personal_pronouns(file):\n",
    "    pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b(?:{})\\b'.format('|'.join(pronouns)), data)\n",
    "\n",
    "        for word in words:\n",
    "           \n",
    "            if word.lower() != 'us':\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "dataset_file = \"48.txt\"\n",
    "pronoun_count = count_personal_pronouns(dataset_file)\n",
    "print(\"Number of personal pronouns mentioned:\", pronoun_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3819f7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cfe5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa073ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
