{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5fb1ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yg\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\yg\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "import sys\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "try:\n",
    "    \n",
    "    \n",
    "    page=requests.get('https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-2/')\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    error_type, error_obj, error_info = sys.exc_info()\n",
    "    print('Error for link :',url)\n",
    "    print(error_type,'Line :',error_info.tb_lineno)\n",
    "    \n",
    "    \n",
    "time.sleep(2)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "links=soup.find_all('h1',attrs={'class':'entry-title'})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04068fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lessons from the past: Some key learnings relevant to the coronavirus crisis\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b66ef4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "“The more you know about the past, the better prepared you are for the future.”\n",
      "Theodore Roosevelt\n",
      "As we speak, the world finds itself engulfed in one of its worst crises in recent times. The global COVID-19 pandemic has caused never-seen-before disruption in both public and economic life. Not only have factories shut down or supply chains abruptly stopped or millions of workers stranded, but festivals suspended, families separated across countries and public-healthcare systems put under tremendous stress. Such a scenario is a first-time for many, but the world has been through pandemics of a similar scale and nature before, and after the due struggle, emerged victoriously. As the more experienced amongst us would remember, the SARS and MERS outbreaks in the early 2000s presented a similar scenario, although at a much lower rate of infection, yet with higher rates of morbidity. Going back further in time, the 1918 Spanish Flu brought a world just out of the first world war, to a standstill. Considered to be the worst amongst modern-era pandemics, the Influenza pandemic affected one-third of the world’s population and 50 million lives. Yet, preventive measures such as social-distancing, quarantine, mass-vaccinations, public support, and restraint have proved to be successful in all such situations, even being effective in occasional plague outbreaks across the world. We face a similar situation today – an extremely infectious virus, which has already spread globally, confined people to their homes and is causing tremendous economic loss every minute economic activity remains suspended, affecting both the government and the industries alike. \n",
      "Can past similar incidents guide industries in such trying times? Can our governments take note of how public-policy measures adopted during the Spanish flu, SARS and MERS outbreak helped in eliminating such pandemics?\n",
      "What can the Government learn?\n",
      "The panic due to the outbreak of COVID-19, and more importantly, the lockdown measures to deal with it, are quite similar to those during the 1918 Influenza Pandemic, or as it is more commonly referred to as, the Spanish Flu. Large cities around the world were put under strict lockdowns, and businesses worldwide came to a grinding halt as large chunks of the population became bedridden.\n",
      "The immediate consequences were the same as the ones observed in the past few weeks – rampant unemployment, supply shortages, and heavy reliance on social security systems, causing a sudden strain on national economic resources.\n",
      "Impact & Learnings\n",
      "Information & Censorship\n",
      "Effective and transparent communications are one of the most crucial and useful tools in disease control. Iran presents a great example of the damage that can be unleashed by a media-blackout. Secondly, censorship might not be the best way to appease the masses during such times. The long-term political impact of media censorship and manipulation of epidemic-related facts in China is yet to be seen. Still, the short-term international unrest and dissent have only deteriorated international relations. At the risk of quoting a cliché as well as the established Streisand effect, the truth always comes out, no matter how many countries try to hide it.\n",
      "Isolation, Lockdown & Distancing Mechanisms Work\n",
      "The Spanish Flu spread was aggravated due to the failure of policymakers in adopting effective containment measures. Research shows that US cities which undertook measures to reduce contact amongst citizens in early-1918 displayed significantly lower peak death rates compared to cities that failed to or were too late to adopt disease containment policies.\n",
      "To quote the results from this 2007 study, “Consistent with this hypothesis, cities in which multiple interventions were implemented at an early phase of the epidemic had peak death rates ≈50% lower than those that did not and had less-steep epidemic curves. They also displayed lower cumulative mortality.”\n",
      "                            1: Contrasting the Death Rates in Philadelphia v. St. Louis during the 1918 Influenza Outbreak\n",
      "1: Contrasting the Death Rates in Philadelphia v. St. Louis during the 1918 Influenza Outbreak\n",
      "As one might guess, Philadelphia was late to levy restrictions on gatherings, parades, and social distancing measures, whereas St. Louis was not.\n",
      "From the same study, we see the definition of a popular phrase “flattening the curve” emerging – which is spreading out the rate of infection over time, enabling health care systems to treat people in a staggered manner, in line with available resources. And, to further corroborate this result, the following graph from the same study shows the different trajectories followed by the disease in two cities of the US.\n",
      "Hence, regardless of the multiple debunking claims of social-distancing & lockdown as an effective preventive mechanism, previous epidemics have taught us that they perform a marvelous job at ‘flattening the curve’.\n",
      "Premature Relaxation can be Disastrous\n",
      "Social Distancing & Lockdown measures are effective, only if sustained, at least for a few months, even after things start to improve.\n",
      "Markel (2007), shows the disastrous consequences that the early relaxation of bans on public gatherings in St. Louis had on death rates, during the Spanish flu. The pullback of social distancing measures to pursue economic interests was premature and caused a sudden, unprecedented surge in the number of deaths due to the flu.\n",
      " 2: Deaths due to the Spanish Flu in St. Louis – A Wider Picture. The black & grey lines show the duration for which social-distancing measures were active.\n",
      "2: Deaths due to the Spanish Flu in St. Louis – A Wider Picture. The black & grey lines show the duration for which social-distancing measures were active.\n",
      "Another peak in death rates was observed only in cities that had relaxed distancing measures prematurely. Hence, it is crucial to consider this past artifact when governments compare the inconveniences to the public & damage caused to the economy due to such measures, with the benefits to the nation in terms of human life saved, and then make the call as to when the restrictions must be eased.\n",
      "What can the industry learn?\n",
      "The industry has played a key role in the obscure fight against the worldwide outbreak. But it faces its fair share of challenges, in such unprecedented times.\n",
      "Supply Shortages, due to shut-down of factories & production houses and the uncertainty of when production systems would resume to normal functioning.Transport disruptions, due to closure & quarantining of cities and state-borders; nation-wide lockdowns bringing all transportation to a standstill; significant disruptions in the supply-chains of most goods.Labour issues, with restrictions on movement, come issues of labour welfare, unrest and employment security. This problem is even more serious if the labour force is migratory in nature.\n",
      "Global industries have weathered through multiple natural disasters and two epidemics of a similar scale and nature. Their recovery-paths have immense strategic implications for current policy-makers and offer strategic insights, helping companies chart out their short-term & long-term strategies.\n",
      "3: This graph looks at the retail sales impact of the SARS epidemic in China in 2003; the earthquake, tsunami and Fukushima nuclear disaster in Japan in 2011; and the MERS epidemic in South Korea in 201.5\n",
      "3: This graph looks at the retail sales impact of the SARS epidemic in China in 2003; the earthquake, tsunami and Fukushima nuclear disaster in Japan in 2011; and the MERS epidemic in South Korea in 201.5\n",
      "Three phases characterise the impact on the retail market in all these three cases:\n",
      "ShockRecoveryStabilization\n",
      "The paths inevitably converge to stabilization but follow different trajectories, and are swayed by public perceptions and externalities, as in the case of the mid-autumn festival in South Korea. Looking at the retail sector from a micro-lens, past crises show that demand trends vary amongst product categories, both during and post the crisis. The three categories usually follow such trends:\n",
      "Demand Trends during & post a Pandemic-generated Crisis\n",
      "4: Demand Trends during & post a Pandemic-generated Crisis\n",
      "4: Demand Trends during & post a Pandemic-generated Crisis[1]\n",
      "These three trends are a valuable tool for both large scale players and regional retailers who now have the means to prioritize and predict consumer-demand and consequently alleviate a sudden strain on the product supply chain arising out of sudden & unexpected demands.\n",
      "Change in Consumer Behaviour\n",
      "A peculiar outcome of such epidemics have been the somewhat permanent changes instilled in consumer buying trends across the inflicted regions, across product categories – Fresh staples see a sharp rise in their demand and product hygiene & safety standards are ranked higher up in the consumers’ priority list. Hence, the advantage lies with producers who can quickly integrate changed consumer-preferences in their products, showcase product reliability & quality, and priced competitively, given the prevalent context. Lastly, previous pandemics have consolidated a long-standing theory, which is true not just for the retail sector but for any consumer-centric industry that there is, – Consumer Loyalty is tried and tested during these times. Effective Consumer Relationship Management (CRM) can forge bonds that go a long way, weathering through the thick and thin in such unprecedented times.\n",
      "Implications\n",
      "Almost two decades ago, the SARS outbreak in China had pushed entrepreneurs and established players to embrace the dawn of the e-commerce era. This outbreak is expected to accelerate further the shift from conventional brick-mortar based commerce to a centralized online cloud-store based mechanism. Survival, in the FMCG sector at least, will be decided to a great extent by the breadth of the supply chain networks and the ability to overcome severe bottlenecks.\n",
      "The past has shown that even though established large-scale players with deep pockets and extensive networks, have a likelier chance to tough it through these hard times, even the regional players & SMEs make it through, strengthened by community-support, empathy and most importantly, local relationships.\n",
      "What did we fail to learn?\n",
      "This global pandemic outbreak has made one thing painfully clear – there is a lack of global collaborative research on ways to combat the spread of such infectious diseases. In the words of Johan Neyts, professor of virology and president of the Belgian-based, International Society for Antiviral Research (ISAR), health authorities failed to incorporate the learnings of the SARS outbreak of the early 2000s, partly because of the economic crisis of 2008 which squeezed funds from any potential research that could have been undertaken and partly because of the lack of seriousness in authorities in considering the efforts involved in dealing with the future expected breaks of coronavirus due to its seven different strains in existence. \n",
      "The Way forward?\n",
      "All of these lessons come with a caveat – Things change with time. The modes of communication have changed. Both information & travel is much more accessible now. We have fast planes & faster internet. We have better healthcare capabilities and a much better, if not perfect, healthcare system. In 1918, people didn’t even know that a virus was causing the pandemic until much after its eradication. Today, we already have extensive research going on for 70 different probable vaccines for the virus, with a record setting pace in clinical trials and approvals.\n",
      "We are much better equipped than what we were 100 years ago, and at the same time, somewhat under-equipped to deal with it. But these lessons from the various similar crises that humanity has faced and risen from, act as a glimmer of hope in these dire times, and if put to good use, can aid in the fight against COVID-19. In the words of Howard Markel, “There’s never been a better time in human history to have a pandemic than today, with the exception of next week or a month later. You want to kick that can down the road, but it’s here today.”\n",
      "Blackcoffer Insights 17: Nishant Kumar Satyam,Vasu Golyan\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links=soup.find_all('div',attrs={'class':'td-post-content tagdiv-type'})\n",
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb810f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive score: 37\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total positive score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '117.txt'\n",
    "positive_words_file = 'positive.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb342400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative score: 61\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='latin-1') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='latin-1') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total negative score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '117.txt'\n",
    "positive_words_file = 'negative-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31bbc485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 1934\n"
     ]
    }
   ],
   "source": [
    "def count_total_words(dataset_file):\n",
    "   \n",
    "    with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    \n",
    "    words = content.split()\n",
    "\n",
    "    \n",
    "    total_words = len(words)\n",
    "\n",
    "    return total_words\n",
    "\n",
    "\n",
    "dataset_file = '117.txt'\n",
    "\n",
    "\n",
    "total_words = count_total_words(dataset_file)\n",
    "\n",
    "\n",
    "print(\"Total number of words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2189fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 258\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import re\n",
    "dataset_file = \"117.txt\"\n",
    "dictionary = pyphen.Pyphen(lang='en')\n",
    "def count_syllables(word):\n",
    "    return len(dictionary.inserted(word).split('-'))\n",
    "def count_complex_words(file):\n",
    "    complex_word_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', data)  \n",
    "\n",
    "        for word in words:\n",
    "            syllable_count = count_syllables(word)\n",
    "            if syllable_count > 2:\n",
    "                complex_word_count += 1\n",
    "\n",
    "    return complex_word_count\n",
    "complex_words_count = count_complex_words(dataset_file)\n",
    "print(\"Number of complex words:\", complex_words_count)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23bc9007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 72\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def count_sentences(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', data)\n",
    "        sentence_count = len(sentences)\n",
    "\n",
    "    return sentence_count\n",
    "dataset_file = \"117.txt\"\n",
    "sentence_count = count_sentences(dataset_file)\n",
    "print(\"Number of sentences:\", sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20242568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total number of characters: 10329\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_character_count(file):\n",
    "    total_character_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split() \n",
    "\n",
    "        for word in words:\n",
    "            total_character_count += len(word)\n",
    "\n",
    "    return total_character_count\n",
    "dataset_file = \"117.txt\"\n",
    "character_count = calculate_total_character_count(dataset_file)\n",
    "print(\"Sum of total number of characters:\", character_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69d6b959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words present in data set: 823\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total stop words present in data set:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '117.txt'\n",
    "positive_words_file = 'all-stop-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbca93a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the dataset file: 2996\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    exceptions = ['es', 'ed']\n",
    "    count = 0\n",
    "    prev_char_vowel = False\n",
    "\n",
    "    if word[-2:] in exceptions:\n",
    "        return count\n",
    "\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            if not prev_char_vowel:\n",
    "                count += 1\n",
    "            prev_char_vowel = True\n",
    "        else:\n",
    "            prev_char_vowel = False\n",
    "\n",
    "    return count\n",
    "\n",
    "def sum_syllables_in_file(file):\n",
    "    total_syllables = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_syllables += count_syllables(word)\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "dataset_file = \"117.txt\"\n",
    "total_syllables = sum_syllables_in_file(dataset_file)\n",
    "print(\"Total syllables in the dataset file:\", total_syllables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4009adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of personal pronouns mentioned: 5\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_personal_pronouns(file):\n",
    "    pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b(?:{})\\b'.format('|'.join(pronouns)), data)\n",
    "\n",
    "        for word in words:\n",
    "            # Exclude the word 'US' (country name)\n",
    "            if word.lower() != 'us':\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "dataset_file = \"117.txt\"\n",
    "pronoun_count = count_personal_pronouns(dataset_file)\n",
    "print(\"Number of personal pronouns mentioned:\", pronoun_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90f48147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 10329\n",
      "Total words: 1934\n",
      "Average word length: 5.340744570837642\n"
     ]
    }
   ],
   "source": [
    "def calculate_word_stats(file):\n",
    "    total_characters = 0\n",
    "    total_words = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_characters += len(word)\n",
    "            total_words += 1\n",
    "\n",
    "    return total_characters, total_words\n",
    "\n",
    "dataset_file = \"117.txt\"\n",
    "char_count, word_count = calculate_word_stats(dataset_file)\n",
    "average_word_length = char_count / word_count if word_count != 0 else 0\n",
    "\n",
    "print(\"Total characters:\", char_count)\n",
    "print(\"Total words:\", word_count)\n",
    "print(\"Average word length:\", average_word_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3007e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
