{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee0bb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yg\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\yg\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "import sys\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "try:\n",
    "    \n",
    "    \n",
    "    page=requests.get('https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/')\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    error_type, error_obj, error_info = sys.exc_info()\n",
    "    print('Error for link :',url)\n",
    "    print(error_type,'Line :',error_info.tb_lineno)\n",
    "    \n",
    "    \n",
    "time.sleep(2)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "links=soup.find_all('h1',attrs={'class':'entry-title'})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063fd979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Jobs Will Robots Take From Humans in The Future?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0f2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In future or in upcoming years humans and machines are going to work together in every field of work. In upcoming days machines will be the need for every human being. Machines [AI technology] will do the work which humans are incapable of doing. Machines will partner and co-operate with humans.\n",
      "According to the professor at the university of Washington, he explained that, as a result of AI, there will be more demand for existing jobs and new jobs will be created that are unimaginable today. Human workers and machines will work together flawlessly, complementing each other. Machines will learn to carry out easier tasks such as following processes or crunching data. They will also help the humans while difficult. Machines or AI will create a great job opportunities for humans in future. John Kelly ll, executive vice president of IBM once said that “Man and Machines working together always beat or make a better decision than a man or a machine independently.”\n",
      " In future, the three sectors of our country like agriculture sector, industrial sector and service sector are going to utilize the machines. So, that their work becomes not difficult. As of now, we can only see that for agriculture purposes various kinds of machines are used which we called as a modern farming method. Some major technologies [machines] that are harvest automation, autonomous tractors, seeding, and weeing and drones. As a result, farms can do agriculture peacefully. In the industrial sector also humans and machines are working together to increase production. Various types of machines are used in industries such as packing machines, loading machine etc. humans provide instructions to the machines and maintain the management in the company. Soon robots [machines] will assist doctors with surgeries. For instance, a doctor at remote location could direct a surgical robot to perform an open heart surgery. But the approaches option and decision will be left to experience and wisdom of the doctor not the robot.\n",
      "What do you think of machines if they will make humans less or more in the field? Machines will push human professionals up the skillset ladder into uniquely human skills such as creativity, social abilities, empathy, and sense-making, which machines cannot automate. As a result, machines will make the workplace more, not less for humans. However, humans have to learn new skills throughout their lives. It is said that in the future 80% of process-oriented tasks will be done by machines. Quantitative reasoning tasks will be done approximately 50% by humans and 50% by machines, while humans will continue to do more than 80% of cross-functional reasoning tasks. According to Harvard research machines, algorithms can read diagnostic scans with 92% accuracy. Humans can do it with 96% accuracy. Together, it will be 99% accurate.\n",
      "Human-machine collaboration enables companies to interact with employees and customers in the novel, more effective ways. Smart machines are helping humans to expand their abilities in three ways. They can amplify our cognitive strengths; interact with customers and employees to free us from higher-level tasks, and embody human skills to extend our physical capabilities. In the research, it was found that 1,500 companies achieve the most significant performance improvement when humans and machines work together. New machine systems have beyond-human cognitive abilities, which many of us fear could potentially dehumanize the future of work. Machines will indeed automate most repetitive and physical tasks, and part of quantitative tasks such as programming and even data science. According to D.E Shaw Group and professor at the University of Washington, explained that, as a result of machines, there will be more demand for existing jobs, and new jobs will be created that are unimaginable today. This is similar to how we couldn’t imagine a web app developer decades ago, and now millions make a living doing that today.\n",
      "Machines are good at doing tasks with speed, precision, and accuracy. But machines are not very good at responding to unknown situations or making judgments. That part will be left to humans. Hence, the need for both humans and machines will be there in the future. Humans and machines have divergent skill sets that, when combined can transform the way we work. Machines have already infiltrated every aspect of our lives, and we must learn to live with them. In the future, human workers will interact more closely with humans.         \n",
      "Blackcoffer Insights 29: Vachika Sharma, ANAND ENGLISH MEDIUM SCHOOL\n",
      "                \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links=soup.find_all('div',attrs={'class':'td-post-content tagdiv-type'})\n",
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93315487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive score: 20\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total positive score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '43.txt'\n",
    "positive_words_file = 'positive.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db492eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative score: 9\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='latin-1') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='latin-1') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total negative score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '43.txt'\n",
    "positive_words_file = 'negative-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75c10c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 747\n"
     ]
    }
   ],
   "source": [
    "def count_total_words(dataset_file):\n",
    "   \n",
    "    with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    \n",
    "    words = content.split()\n",
    "\n",
    "    \n",
    "    total_words = len(words)\n",
    "\n",
    "    return total_words\n",
    "\n",
    "\n",
    "dataset_file = '43.txt'\n",
    "\n",
    "\n",
    "total_words = count_total_words(dataset_file)\n",
    "\n",
    "\n",
    "print(\"Total number of words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c363edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 95\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import re\n",
    "dataset_file = \"43.txt\"\n",
    "dictionary = pyphen.Pyphen(lang='en')\n",
    "def count_syllables(word):\n",
    "    return len(dictionary.inserted(word).split('-'))\n",
    "def count_complex_words(file):\n",
    "    complex_word_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', data)  \n",
    "\n",
    "        for word in words:\n",
    "            syllable_count = count_syllables(word)\n",
    "            if syllable_count > 2:\n",
    "                complex_word_count += 1\n",
    "\n",
    "    return complex_word_count\n",
    "complex_words_count = count_complex_words(dataset_file)\n",
    "print(\"Number of complex words:\", complex_words_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d9f1226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 46\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def count_sentences(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', data)\n",
    "        sentence_count = len(sentences)\n",
    "\n",
    "    return sentence_count\n",
    "dataset_file = \"43.txt\"\n",
    "sentence_count = count_sentences(dataset_file)\n",
    "print(\"Number of sentences:\", sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c96525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total number of characters: 3896\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_character_count(file):\n",
    "    total_character_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split() \n",
    "\n",
    "        for word in words:\n",
    "            total_character_count += len(word)\n",
    "\n",
    "    return total_character_count\n",
    "dataset_file = \"43.txt\"\n",
    "character_count = calculate_total_character_count(dataset_file)\n",
    "print(\"Sum of total number of characters:\", character_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d723958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words present in data set: 341\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total stop words present in data set:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '43.txt'\n",
    "positive_words_file = 'all-stop-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47be3084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the dataset file: 1160\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    exceptions = ['es', 'ed']\n",
    "    count = 0\n",
    "    prev_char_vowel = False\n",
    "\n",
    "    if word[-2:] in exceptions:\n",
    "        return count\n",
    "\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            if not prev_char_vowel:\n",
    "                count += 1\n",
    "            prev_char_vowel = True\n",
    "        else:\n",
    "            prev_char_vowel = False\n",
    "\n",
    "    return count\n",
    "\n",
    "def sum_syllables_in_file(file):\n",
    "    total_syllables = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_syllables += count_syllables(word)\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "dataset_file = \"43.txt\"\n",
    "total_syllables = sum_syllables_in_file(dataset_file)\n",
    "print(\"Total syllables in the dataset file:\", total_syllables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b15fb484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of personal pronouns mentioned: 5\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_personal_pronouns(file):\n",
    "    pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b(?:{})\\b'.format('|'.join(pronouns)), data)\n",
    "\n",
    "        for word in words:\n",
    "           \n",
    "            if word.lower() != 'us':\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "dataset_file = \"43.txt\"\n",
    "pronoun_count = count_personal_pronouns(dataset_file)\n",
    "print(\"Number of personal pronouns mentioned:\", pronoun_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f181b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
