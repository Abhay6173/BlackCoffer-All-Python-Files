{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e28510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yg\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\yg\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "import sys\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "try:\n",
    "    \n",
    "    \n",
    "    page=requests.get('https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/')\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    error_type, error_obj, error_info = sys.exc_info()\n",
    "    print('Error for link :',url)\n",
    "    print(error_type,'Line :',error_info.tb_lineno)\n",
    "    \n",
    "    \n",
    "time.sleep(2)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "links=soup.find_all('h1',attrs={'class':'entry-title'})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9324fb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environmental impact of the COVID-19 pandemic – Lesson for the Future\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed41066a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Covid- 19 pandemics forced factories to shut down, flights getting canceled and a massive decrease in the global economy, with a significant decrease in Green House Gases (GHG) in many developed and developing countries.\n",
      "The SARS- CoV2 came into the spotlight in December 2019 and has impacted most of the countries till then. Nearly 131 million peoples were infected worldwide and resulting in deaths of around 2.9 Million according to World Health Organisation (WHO). Most of the countries dealt with the new virus by imposing strict lockdowns and social distancing to control the spread of the virus. These policies caused adverse effects worldwide. One of the most important impacts of the Covid-19 Pandemic is on the environment.\n",
      "There have been few positive impacts on the environment due to lockdown like, air pollution has decreased dramatically, as people were asked to stay in their houses due to the lockdowns. There has also been a sharp decline in environmental noise. Environmental noise can be well defined as the unwanted or harmful outdoor sounds caused by human activities like noise emitted by road traffics, air traffics, rail traffics, and industrial activities. It is one of the most important challenges in the modern era as noise pollution can cause adverse effects on humans as well as harm many animals too. The imposition of lockdown and quarantine by various nation’s governments has caused people to remain back at their homes. Because of this, the movement of people from one place to a different place has reduced significantly and the use of personal and public transport has also decreased. Due to all these changes, the environmental noise generated in most of the cities has dropped substantially.\n",
      "\n",
      "Water Pollution at beaches have reduced significantly and many animals were spotted back in the cities, but the covid-19 virus has also generated many negative and indirect effect on the environment.\n",
      "To begin with, some of the developed countries have halted their sustainability program during the pandemic. In the United States and in many other European nation-States, waste recycling plants have been suspended in many municipalities and cities due to the concern of the virus getting spread at the recycling centers. This has resulted in an increase in the use of single-use plastic bags instead of the re-usable bags by many leading restaurants, firms, and corporations. For instance, Starbucks, a leading coffee company during the month of March 2020, has announced a short-lived ban on the utilization of recyclable and reusable cups.\n",
      "Furthermore, with most of the people staying indoors because of the lockdown majority of the department stores, shops, restaurants, and food outlets are closed, making an online purchase and food delivery are quite high. This has created more consumption and demand for fossil fuels due to the transportation and mobility of these goods to each individual. There has been an enormous upsurge of medical waste- because most of the products employed by healthcare professionals are usually single-use items that can be used only once before they are disposed of. Some of these wastes include used masks, personal protection kits, and gloves. For instance, nearly 200 tons of medical waste were generated during the peak of the pandemic breakout in Wuhan, China. This is 50 tones more than the average waste generated before the outbreak in Wuhan.\n",
      "\n",
      "These organic and inorganic wastes generated due to the policies crafted by the government takes a heavy toll on the environment and can cause environmental issues like water pollution, air pollution, soil erosion, and can harm the local flora and fauna.\n",
      "The demand for masks during the pandemic has become skyrocketing but the materials required for the production of these masks are highly dangerous for the environment as they are generally composed of non-woven fabrics. Polyester, Polystyrene, polyethylene, and polycarbonate, are some common materials used for the surgical mask with density lying between 20grams to 25 grams/sq. meter. These materials are mostly resistant to liquids and are plastic-based products with a really high afterlife after being discarded. If not treated properly without discarding, they end up filling the landfills and the oceans making it dangerous to aquatic lifeforms. For example, recently the environment in Hong Kong has started degrading drastically during the pandemic with the accumulation of these clinical wastes.\n",
      "\n",
      "With recycling plants on hold, piles of small mountains of wastes and their depositions at open areas are formed due to the increasing number of unrecycled wastes generated every day. This makes the surrounding more vulnerable and also creating a high risk of air pollutions as the dumped open wastes decays into Methane (CH4), a greenhouse gas, hence increasing the risk of global warming too.  Not only the surroundings are getting affected by these careless methods, but the local people are also getting affected. If the excess methane gets accumulated in the Earth’s atmosphere due to piles of unrecycled wastes, this could result in increases in Earth’s average temperature and can be harmful to future generations.\n",
      "Many protected and endangered flora and fauna are facing much greater risks due to the imposition of the lockdown. Many countries under lockdown have made people stay inside their homes. The employees, NGOs, and volunteers working in these protected areas like National Parks, Marine Conservation Zones, and wildlife sanctuaries are made to stay at home making these protected and endangered flora and fauna unattended. This has also led to an increase in many illegal activities like wildlife hunting, illegal deforestation, and fishing activities due to the absence of these people. The prohibition of eco-tourism has also led to a significant financial drop in the economy of these protected areas.\n",
      "Some nations like China have asked the local authorities and native government bodies to increase the amount of disinfection routine, mainly to increase the dosage of chlorine in the wastewater treatment plant to prevent the spread of the COVID-19 virus. However, according to WHO (2020), no solid evidence has been found on the survival of the virus on the lifespan of the virus in wastewater as well as in drinking water. Despite the fact that excessive amounts of chlorine in water can cause harmful problems and issues associated with people’s health like bladder cancer and it also damages its cells.\n",
      "The COVID-19 is a reminder that the health of the planet is also linked to the health of humans. Evidence proves that the virus is zoonotic, meaning it can be transmitted between people and animals. They are accountable for seventy-five percent of all emerging infectious diseases in the World. With the Virus infecting millions of people every day across the globe, Various governments and agencies’ top priority is to regulate the spread of the virus by shifting the spotlight on the management and treatment of wastes (especially the clinical and medical waste).  Likewise, at the same time, we as responsible individuals need to step up and follow the necessary guideline and precautions for the disposal of the waste and medical gears.\n",
      "\n",
      "In Spite of various data showing that the pollutions have reduced significantly during the pandemic, History has witnessed a rise in pollution during any “post-financial crisis”.  A similar case was observed during the 2008 financial crash – although there was a temporary decrease in emissions of 1.3% was observed, but as the economy recovered in 2010, emissions were at an all-time high. After all, only through sheer mutual empathy and goodwill that the world will emerge stronger after this global pandemic. To prevent future outbreaks, we must address regularly the threats to the ecosystems and wildlife, including habitat loss, illegal trade, pollution, and climate change as human life depends on Earth’s life.\n",
      "If you live near a spacious outdoor area, like the desert or an empty road lined with trees and you realize it’s the only safe, surface-less space to take a walk in, then you begin to realize the beauty of nature. The point is not to remain indoors, but to avoid being in close contact with others. When you do leave your home, whether it is for a walk in the desert or a run on your street, make sure to wipe down any surfaces you come into contact with, avoid touching your face, and frequently wash your hands.\n",
      "Blackcoffer Insights 27: Saujanya Roy, Indian Maritime University, Kolkata\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links=soup.find_all('div',attrs={'class':'td-post-content tagdiv-type'})\n",
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df00fe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive score: 33\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total positive score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '58.txt'\n",
    "positive_words_file = 'positive.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "455cbca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative score: 60\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='latin-1') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='latin-1') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total negative score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '58.txt'\n",
    "positive_words_file = 'negative-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24f80ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 1388\n"
     ]
    }
   ],
   "source": [
    "def count_total_words(dataset_file):\n",
    "   \n",
    "    with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    \n",
    "    words = content.split()\n",
    "\n",
    "    \n",
    "    total_words = len(words)\n",
    "\n",
    "    return total_words\n",
    "\n",
    "\n",
    "dataset_file = '58.txt'\n",
    "\n",
    "\n",
    "total_words = count_total_words(dataset_file)\n",
    "\n",
    "\n",
    "print(\"Total number of words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d99d629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 183\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import re\n",
    "dataset_file = \"58.txt\"\n",
    "dictionary = pyphen.Pyphen(lang='en')\n",
    "def count_syllables(word):\n",
    "    return len(dictionary.inserted(word).split('-'))\n",
    "def count_complex_words(file):\n",
    "    complex_word_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', data)  \n",
    "\n",
    "        for word in words:\n",
    "            syllable_count = count_syllables(word)\n",
    "            if syllable_count > 2:\n",
    "                complex_word_count += 1\n",
    "\n",
    "    return complex_word_count\n",
    "complex_words_count = count_complex_words(dataset_file)\n",
    "print(\"Number of complex words:\", complex_words_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50115b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 56\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def count_sentences(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', data)\n",
    "        sentence_count = len(sentences)\n",
    "\n",
    "    return sentence_count\n",
    "dataset_file = \"58.txt\"\n",
    "sentence_count = count_sentences(dataset_file)\n",
    "print(\"Number of sentences:\", sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7dcf8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total number of characters: 7261\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_character_count(file):\n",
    "    total_character_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split() \n",
    "\n",
    "        for word in words:\n",
    "            total_character_count += len(word)\n",
    "\n",
    "    return total_character_count\n",
    "dataset_file = \"58.txt\"\n",
    "character_count = calculate_total_character_count(dataset_file)\n",
    "print(\"Sum of total number of characters:\", character_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cad9e538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words present in data set: 627\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total stop words present in data set:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '58.txt'\n",
    "positive_words_file = 'all-stop-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61fce3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the dataset file: 2176\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    exceptions = ['es', 'ed']\n",
    "    count = 0\n",
    "    prev_char_vowel = False\n",
    "\n",
    "    if word[-2:] in exceptions:\n",
    "        return count\n",
    "\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            if not prev_char_vowel:\n",
    "                count += 1\n",
    "            prev_char_vowel = True\n",
    "        else:\n",
    "            prev_char_vowel = False\n",
    "\n",
    "    return count\n",
    "\n",
    "def sum_syllables_in_file(file):\n",
    "    total_syllables = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_syllables += count_syllables(word)\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "dataset_file = \"58.txt\"\n",
    "total_syllables = sum_syllables_in_file(dataset_file)\n",
    "print(\"Total syllables in the dataset file:\", total_syllables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02a47eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of personal pronouns mentioned: 2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_personal_pronouns(file):\n",
    "    pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b(?:{})\\b'.format('|'.join(pronouns)), data)\n",
    "\n",
    "        for word in words:\n",
    "           \n",
    "            if word.lower() != 'us':\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "dataset_file = \"58.txt\"\n",
    "pronoun_count = count_personal_pronouns(dataset_file)\n",
    "print(\"Number of personal pronouns mentioned:\", pronoun_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fe8a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288311c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d04a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
