{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97552c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yg\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\yg\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "import sys\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "try:\n",
    "    \n",
    "    \n",
    "    page=requests.get('https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation-2/')\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    error_type, error_obj, error_info = sys.exc_info()\n",
    "    print('Error for link :',url)\n",
    "    print(error_type,'Line :',error_info.tb_lineno)\n",
    "    \n",
    "    \n",
    "time.sleep(2)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "links=soup.find_all('h1',attrs={'class':'entry-title'})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5d5f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to the COVID-19 the repercussion of the environment\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6274c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epidemics, in general, have both direct and indirect costs associated with direct and indirect measures adopted to counter (control) the epidemic which generally have both short-run and long-run economic and social consequences. The 2019 Coronavirus (COVID-19) outbreak globally lead a significant setback to the entire globe. The first case was detected on 26th December 2019 in China.  The World Health Organization (WHO) prepared the first diagnostic kit on 14th January 2020.\n",
      "As the global coronavirus or Covid-19 pandemic continues to take hold every economy is feeling it’s effect with a high degree of uncertainty taking a toll in all the manufacturing sectors. Supply chain management is an important area with many opportunities for our community to contribute in various forms.  According to the data produced by Supply Management’s Report on Business show that PMI (Purchasing Manager’s Index) has declined 1% in the month of February. Mainly there has been a huge contraction in the Petroleum, Transportation and Textile Industries. Although there has been a fall in the inventory but is expected to grow due to supply chain disruptions leading to inefficiencies in material conversion and continued advanced stocking to protect production schedules. A analysis by trading platform Forex claimed that heavily 75% of all companies had already reported supply chain disruptions with more than 80% believing that at some point they would experience impacts as a result of Covid-19 disruptions. The effective shutdown of industrial activity i.e. China, ground zero for the virus presented particularly difficult problems for manufacturing firms worldwide. Imported goods invested by investors set a significant setback.\n",
      "Several experiments were carried out by different governments across the globe to restrict the spread of this pandemic. Boris Johnson introduced the herd immunity plan in the United Kingdom which was a failure followed by a mitigate model which India also tried initially to stop the spread of the Covid-19 virus. The last and the ultimate model that most of the countries are applying is the Hammer and the Dance Model i.e. the Lockdown Model which is estimated to bring down the caseload by 25-30%. The Lockdown model basically means buying time to prepare the vaccine to kill the virus.\n",
      "However, the lockdown has certain critical economic consequences which add to the burden of global distress. This can be explained using the standard macroeconomic Keynesian model. The lockdown and the spread of the disease have a direct negative shock on aggregate consumption levels and exports. This leads to a contraction in aggregate demand which leads to a fall in the market rate of interest and aggregate equilibrium output. The secondary effect on the commodity market is via investment demand function which can either increase owing to a fall in the market rate of interest, or fall owing to the contraction in aggregate demand. Clearly, the contraction of the Aggregate Demand-side generates an economic slowdown. On the other hand, restriction of workers gathering in the workplace owing to lockdown hurts the production in those sectors which need the presence of physical workers. Note that software or financial service-producing sectors are exempted from such negative supply shock at least in the short-run to medium-run since those works could be easily carried out based on “work from home” anthem. However, reverse migration of workers is an indication of a sharp cut down in production activities. This Aggregate supply shock leads to the situation of stagflation. In recent announcements by the Reserve Bank of India (RBI) to ease liquidity in the system may prove to be counterproductive provided the aggregate supply shock, since the escalation of demand specifically for non-traded products without an adequate increase in production (supply) would only result in inflation. In other words, supply-side management must go hand in hand with demand-side policies. Even if policies are undertaken at the national level by the government, however, conditions may not improve much due to shocks in the external sector through trade in commodities. Most imports are banned which will increase the economic cost of production of import substitutes within the domestic territory based on the theory of comparative advantage in a Ricardian sense. At the same time, exports are hurt due to lower demand from the developed economies. This shows that unemployment and inflation are inevitable in the near future.\n",
      "Corona Virus has mainly affected raw material export-driven countries. With the Covid-19 virus in the backdrop there will be a decline in new orders, production, and employment with ease in supplier deliveries as demand will be less with a mild decline in the inventories. There has been a huge revenue impact. Long stretches of empty supermarket shelves and shortage of essential commodities are only the visible impacts to consumers of the global chain disruption caused by the Covid-19 pandemic. The uncertainties ahead swing between extremes. As the shortages worsen before they get resolved prices of many commodities could go up for consumers even if laws exist against price gouging. At the same time we should keep in mind that constrained supplies could cause a decline in demand which in turn may end up weakening prices. Risk Management process is not robust enough to cope with the fallout of the coronavirus pandemic. The seemingly relentless forces of globalization and technology with coronavirus in the backdrop will present us with new supply chain challenges and opportunities for further progress in the near future. There is a glimmer of good news as countries globally haven taken preventive measures but the recovery may be fragile.\n",
      "The crisis due to the global pandemic is likely to be more serious for developing economies compared to the global financial crisis of 2008. This is due to the fact that the global financial crisis leads to lower demand for exports from the developing economies by the developed nations which further lead to contraction of export-based industries and other sectors in the developing nations due to inter-sectoral backward and forward linkage effect, however, the burden of retrenchments in the formal sector was absorbed in the informal sector. In the present situation, the problem of vanishing informal sector is evident since informal sector workers are more vulnerable to the spread of the disease due to the absence of non-regulatory authority and out of direct government control. Moreover, lockdown lead to massive close down of this informal units, thus the informal sector in this present set up is vanishing due to which the shock absorption capacity of developing economy like India is becoming weaker. The global economy is drowning towards deep cycles of economic depression and the aftershocks seem to be long-lasting. The only way of this global shock seems to be international policy coordination in line with the needs of the domestic economies\n",
      "Blackcoffer Insights 18: Anusil Das, St.Xavier's University\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links=soup.find_all('div',attrs={'class':'td-post-content tagdiv-type'})\n",
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972a333e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive score: 28\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total positive score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '104.txt'\n",
    "positive_words_file = 'positive.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7380bca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative score: 48\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='latin-1') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='latin-1') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total negative score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '104.txt'\n",
    "positive_words_file = 'negative-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5324079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 1129\n"
     ]
    }
   ],
   "source": [
    "def count_total_words(dataset_file):\n",
    "   \n",
    "    with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    \n",
    "    words = content.split()\n",
    "\n",
    "    \n",
    "    total_words = len(words)\n",
    "\n",
    "    return total_words\n",
    "\n",
    "\n",
    "dataset_file = '104.txt'\n",
    "\n",
    "\n",
    "total_words = count_total_words(dataset_file)\n",
    "\n",
    "\n",
    "print(\"Total number of words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239f5951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 258\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import re\n",
    "dataset_file = \"117.txt\"\n",
    "dictionary = pyphen.Pyphen(lang='en')\n",
    "def count_syllables(word):\n",
    "    return len(dictionary.inserted(word).split('-'))\n",
    "def count_complex_words(file):\n",
    "    complex_word_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', data)  \n",
    "\n",
    "        for word in words:\n",
    "            syllable_count = count_syllables(word)\n",
    "            if syllable_count > 2:\n",
    "                complex_word_count += 1\n",
    "\n",
    "    return complex_word_count\n",
    "complex_words_count = count_complex_words(dataset_file)\n",
    "print(\"Number of complex words:\", complex_words_count)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d59e4cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 72\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def count_sentences(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', data)\n",
    "        sentence_count = len(sentences)\n",
    "\n",
    "    return sentence_count\n",
    "dataset_file = \"117.txt\"\n",
    "sentence_count = count_sentences(dataset_file)\n",
    "print(\"Number of sentences:\", sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64701548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total number of characters: 10329\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_character_count(file):\n",
    "    total_character_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split() \n",
    "\n",
    "        for word in words:\n",
    "            total_character_count += len(word)\n",
    "\n",
    "    return total_character_count\n",
    "dataset_file = \"117.txt\"\n",
    "character_count = calculate_total_character_count(dataset_file)\n",
    "print(\"Sum of total number of characters:\", character_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edba3d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words present in data set: 500\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total stop words present in data set:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '104.txt'\n",
    "positive_words_file = 'all-stop-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28fc83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the dataset file: 1835\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    exceptions = ['es', 'ed']\n",
    "    count = 0\n",
    "    prev_char_vowel = False\n",
    "\n",
    "    if word[-2:] in exceptions:\n",
    "        return count\n",
    "\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            if not prev_char_vowel:\n",
    "                count += 1\n",
    "            prev_char_vowel = True\n",
    "        else:\n",
    "            prev_char_vowel = False\n",
    "\n",
    "    return count\n",
    "\n",
    "def sum_syllables_in_file(file):\n",
    "    total_syllables = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_syllables += count_syllables(word)\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "dataset_file = \"104.txt\"\n",
    "total_syllables = sum_syllables_in_file(dataset_file)\n",
    "print(\"Total syllables in the dataset file:\", total_syllables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cddfde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of personal pronouns mentioned: 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_personal_pronouns(file):\n",
    "    pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b(?:{})\\b'.format('|'.join(pronouns)), data)\n",
    "\n",
    "        for word in words:\n",
    "            # Exclude the word 'US' (country name)\n",
    "            if word.lower() != 'us':\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "dataset_file = \"104.txt\"\n",
    "pronoun_count = count_personal_pronouns(dataset_file)\n",
    "print(\"Number of personal pronouns mentioned:\", pronoun_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd5957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 6063\n",
      "Total words: 1129\n",
      "Average word length: 5.370239149689991\n"
     ]
    }
   ],
   "source": [
    "def calculate_word_stats(file):\n",
    "    total_characters = 0\n",
    "    total_words = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_characters += len(word)\n",
    "            total_words += 1\n",
    "\n",
    "    return total_characters, total_words\n",
    "\n",
    "dataset_file = \"104.txt\"\n",
    "char_count, word_count = calculate_word_stats(dataset_file)\n",
    "average_word_length = char_count / word_count if word_count != 0 else 0\n",
    "\n",
    "print(\"Total characters:\", char_count)\n",
    "print(\"Total words:\", word_count)\n",
    "print(\"Average word length:\", average_word_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cae9852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20256744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc6cacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f37d56f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
