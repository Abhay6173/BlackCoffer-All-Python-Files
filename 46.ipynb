{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b332c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yg\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\yg\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yg\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "import sys\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "try:\n",
    "    \n",
    "    \n",
    "    page=requests.get('https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/')\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    error_type, error_obj, error_info = sys.exc_info()\n",
    "    print('Error for link :',url)\n",
    "    print(error_type,'Line :',error_info.tb_lineno)\n",
    "    \n",
    "    \n",
    "time.sleep(2)\n",
    "soup=BeautifulSoup(page.text,'html.parser')\n",
    "links=soup.find_all('h1',attrs={'class':'entry-title'})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c03b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning impact on areas of e-learning?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c42cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eLearning as technology becomes more affordable in higher education but having a big barrier in the cost of developing its resources. Deep learning using artificial intelligence continues to become more and more popular and having impacts on many areas of eLearning. It offers online learners of the future intuitive algorithms and automated delivery of eLearning content through modern LMS platforms. This paper aims to survey various applications of deep learning approaches for developing the resources of the eLearning platform, in which predictions, algorithms, and analytics come together to create more personalized future eLearning experiences. In addition, deep learning models for developing the contents of the eLearning platform, deep learning framework that enable deep learning systems into eLearning and its development, benefits & future trends of deep learning in eLearning, the relevant deep learning-based artificial intelligence tools, and a platform enabling the developer and learners to quickly reuse resources are clearly summarized. Thus, deep learning has evolved into developing ways to re-purpose existing resources that can mitigate the expense of content development of future eLearning.\n",
      "It is natural to wonder where you might get AI tools to avoid the time and expense of developing your own. Don’t worry about the advert of AIaaS or “AI as a Service” even small education or learning & development professionals can purchase the license of AI tools and components. However, such types of tools cannot be useful for every e-learning ecosystem but may offer some enticing benefits such as adding standard AI tasks (logic, decision making) to your toolbox. Here are some of the AIaaS tools and platforms offered by famous tech giants most of which are cloud-based.\n",
      "Microsoft Azure\n",
      "Cloud-based AI services that can be used to build and manage AI applications like image recognition or bot-based apps\n",
      "IBM’s Watson\n",
      "Cloud-based AI services that can be integrated into your applications; to store and manage your own data\n",
      "Google’s Tensor Flow\n",
      " An end-to-end open-source machine learning platform\n",
      "Amazon Web Services\n",
      "Offers a wide range of products and services on Amazon’s cloud\n",
      "There are other AIaaS platforms such as DataRobot, Petuum, and H2O which shows that the field is expanding.AI will probably not make human workers obsolete, at least not for a long time To put some of your fears to bed: the robots are probably not coming for your jobs, at least not yet. Given how artificial intelligence has been portrayed in the media, in particular in some of our favorite sci-fi movies, it’s clear that the advent of this technology has created fear that AI will one day make human beings obsolete in the workforce. After all, as technology has advanced, many tasks that were once executed by human hands have become automated. It’s only natural to fear that the leap toward creating intelligent computers could herald the beginning of the end of work as we know it. But, I don’t think there is any reason to be so fatalistic. A recent paper published by the MIT Task Force on the Work of the Future entitled “Artificial Intelligence And The Future of Work,” looked closely at developments in AI and their relation to the world of work. The paper paints a more optimistic picture.\n",
      "Rather than promoting the obsolescence of human labor, the paper predicts that AI will continue to drive massive innovation that will fuel many existing industries and could have the potential to create many new sectors for growth, ultimately leading to the creation of more jobs. While AI has made major strides toward replicating the efficacy of human intelligence in executing certain tasks, there are still major limitations. In particular, AI programs are typically only capable of “specialized” intelligence, meaning they can solve only one problem, and execute only one task at a time. Often, they can be rigid, and unable to respond to any changes in input, or perform any “thinking” outside of their prescribed programming. Humans, however, possess “generalized intelligence,” with the kind of problem-solving, abstract thinking, and critical judgment that will continue to be important in business. Human judgment will be relevant, if not in every task, then certainly throughout every level across all sectors. There are many other factors that could limit runaway advancement in AI. AI often requires “learning” which can involve massive amounts of data, calling into question the availability of the right kind of data, and highlighting the need for categorization and issues of privacy and security around such data. There is also the limitation of computation and processing power. The cost of electricity alone to power one supercharged language model AI was estimated at $4.6 million. Another important limitation of note is that data can itself carry bias, and be reflective of societal inequities or the implicit biases of the designers who create and input the data. If there is bias in the data that is inputted into an AI, this bias is likely to carry over to the results generated by the AI.\n",
      "There has even been a bill introduced into Congress entitled the Algorithmic Accountability Act with the goal of forcing the Federal Trade Commission to investigate the use of any new AI technology for the potential to perpetuate bias. Based on these factors and many others, the MIT CCI paper argues that we are a long way from reaching a point in which AI is comparable to human intelligence, and could theoretically replace human workers entirely.  Provided there is an investment at all levels, from education to the private sector and governmental organizations—anywhere that focuses on training and upskilling workers—AI has the potential to ultimately create more jobs, not less. The question should then become not “humans or computers” but “humans and computers” involved in complex systems that advance industry and prosperity. This paper is a fascinating read for anyone hoping to dive deeper into AI and the many potential directions in which it may lead.AI Is becoming standard in all businesses, not just in the world of tech A couple of times recently, AI has come up in conversation with a client or an associate, and I’m noticing a fallacy in how people are thinking about it. There seems to be a sense for many that it is a phenomenon that is only likely to have big impacts in the tech world. In case you hadn’t noticed, the tech world is the world these days. Don’t ever forget when economist Paul Krugman said in 1998 that “By 2005 or so, it will become clear that the Internet’s impact on the economy has been no greater than the fax machine’s.” You definitely don’t want to be behind the curve when it comes to AI.  In fact, 90% of leading businesses already have ongoing investments in AI technologies. More than half of businesses that have implemented some manner of AI-driven technology report experiencing greater productivity. AI is likely to have a strong impact on certain sectors in particular:\n",
      "Medical:\n",
      "The potential benefits of utilizing AI in the field of medicine are already being explored. The medical industry has a robust amount of data, which can be utilized to create predictive models related to healthcare. Additionally, AI has shown to be more effective than physicians in certain diagnostic contexts.\n",
      "Automotive:\n",
      "We’re already seeing how AI is impacting the world of transportation and automobiles with the advent of autonomous vehicles and autonomous navigation. AI will also have a major impact on manufacturing, including within the automotive sector.\n",
      "Cybersecurity:\n",
      "Cybersecurity is front of mind for many business leaders, especially considering the spike in cybersecurity breaches throughout 2020. Attacks rose 600% during the pandemic as hackers capitalized on people working from home, on less secure technological systems, and Wi-Fi networks. AI and machine learning will be critical tools in identifying and predicting threats in cybersecurity. AI will also be a crucial asset for security in the world of finance, given that it can process large amounts of data to predict and catch instances of fraud.\n",
      "E-Commerce:\n",
      "AI will play a pivotal role in e-commerce in the future, in every sector of the industry from user experience to marketing to fulfillment and distribution. We can expect that moving forward, AI will continue to drive e-commerce, including through the use of chat-bots, shopper personalization, image-based targeting advertising, and warehouse and inventory automation.\n",
      "AI can have a big impact on the job search\n",
      "If you are moving forward with the hope that a hiring manager may give you the benefit of the doubt on a small misstep within the application, you might be in for a rude awakening. AI already plays a major role in the hiring process, so much so that up to 75% of resumes are rejected by an automated applicant tracking system, or ATS before they even reach a human being.  In the past, recruiters have had to devote considerable time to poring over resumes to look for relevant candidates. Data from LinkedIn shows that recruiters can spend up to 23 hours looking over resumes for one successful hire.\n",
      "Increasingly, however, resume scanning is being done by AI-powered programs. In 2018, 67% of hiring managers stated that AI was making their jobs easier. Despite the increasing prevalence of automation and algorithms in the hiring process, many have been critical of the use of certain types of AI by hiring managers, based on the charge that it can perpetuate and ever create more bias in hiring. One particular example is illustrated by HireVue, a startup whose initial services included technology that aimed to use facial recognition software and psychology to determine the potential effectiveness of a candidate in a certain role. The Electronic Privacy Information Center filed a lawsuit with the Federal Trade Commission alleging that this software had the potential to perpetuate bias and prejudice. HireVue discontinued the use of facial recognition software in early 2021, and now uses audio analysis and natural language processing. It’s clear that the use of certain types of AI in the hiring process will likely be controversial as new technology develops. However, if potential employers are using AI to process your application, there is no reason that you cannot be utilizing similar technology to your advantage.\n",
      "Jobscan is an excellent resource that provides similar resume scanning to what would be used by a hiring manager. By comparing your resume to a job description, Jobscan will give you information on how to tweak your resume so that it is a good match for a certain position, with the goal of “beating” an applicant tracking system (ATS).\n",
      "Jobseer is a browser add-on, and another great AI-based tool for those on the job market. Based on a scan of your resume, as well as keywords and skills related to your desired jobs, Jobseer will help match you with the job listings that best fit your experience. For each listing, you get a rating based on how well you are aligned with the particular posting, as well as recommendations of skills to add to better position your resume and experience.\n",
      "Rezi: Now, as a disclaimer, I would never encourage you to turn your resume writing over to a bot. But Rezi is an awesome AI-based resume builder that includes templates to help you design a resume that is sure to check the boxes when it comes to applicant tracking systems. This is a great jumping-off point to kickstart a new resume.  Another great way to use this type of tool is to generate a new resume and compare it to your current resume to see how it stacks up, and identify some areas for improvement. AI is also a great place to focus your energy if you are looking to upskill in your career, or make your professional profile more competitive in the job market, especially when you consider that AI will have such far-reaching impacts across many industries.AI and machine learning are at the top of many lists of the most important skills in today’s job market. Jobs requesting AI or machine-learning skills are expected to increase by 71% in the next five years. If you’d like to expand your knowledge base in this arena, consider some of the great free online course offerings that focus on AI skills. If you are tech-savvy, it would be wise to dive deep and learn as much as you can about interacting in the AI space. If your skills lie elsewhere, it is important to recognize that AI will have a big impact, and to the extent of your abilities, you should try to understand the fundamentals of how it functions in different sectors. AI is definitely here to stay, whether we like it or not. Personally, I don’t think we have anything to be afraid of. The best way to move forward is to be aware of and adapt to the new technology around us, AI included. This article was updated on April 16, 2021, to reflect changes in HireVue’s assessment tools.\n",
      "Blackcoffer Insights 28: Monica V, SNS COLLEGE OF TECHNOLOGY\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links=soup.find_all('div',attrs={'class':'td-post-content tagdiv-type'})\n",
    "for i in links:\n",
    "    print(i.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fd73a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive score: 68\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total positive score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '46.txt'\n",
    "positive_words_file = 'positive.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bdc31dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative score: 31\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(main_dataset_file, 'r', encoding='latin-1') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='latin-1') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total negative score:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '46.txt'\n",
    "positive_words_file = 'negative-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae3a81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 2166\n"
     ]
    }
   ],
   "source": [
    "def count_total_words(dataset_file):\n",
    "   \n",
    "    with open(dataset_file, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    \n",
    "    words = content.split()\n",
    "\n",
    "    \n",
    "    total_words = len(words)\n",
    "\n",
    "    return total_words\n",
    "\n",
    "\n",
    "dataset_file = '46.txt'\n",
    "\n",
    "\n",
    "total_words = count_total_words(dataset_file)\n",
    "\n",
    "\n",
    "print(\"Total number of words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9490d5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complex words: 270\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import re\n",
    "dataset_file = \"46.txt\"\n",
    "dictionary = pyphen.Pyphen(lang='en')\n",
    "def count_syllables(word):\n",
    "    return len(dictionary.inserted(word).split('-'))\n",
    "def count_complex_words(file):\n",
    "    complex_word_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', data)  \n",
    "\n",
    "        for word in words:\n",
    "            syllable_count = count_syllables(word)\n",
    "            if syllable_count > 2:\n",
    "                complex_word_count += 1\n",
    "\n",
    "    return complex_word_count\n",
    "complex_words_count = count_complex_words(dataset_file)\n",
    "print(\"Number of complex words:\", complex_words_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "821e3bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 82\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def count_sentences(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', data)\n",
    "        sentence_count = len(sentences)\n",
    "\n",
    "    return sentence_count\n",
    "dataset_file = \"46.txt\"\n",
    "sentence_count = count_sentences(dataset_file)\n",
    "print(\"Number of sentences:\", sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25add327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total number of characters: 10943\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_character_count(file):\n",
    "    total_character_count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split() \n",
    "\n",
    "        for word in words:\n",
    "            total_character_count += len(word)\n",
    "\n",
    "    return total_character_count\n",
    "dataset_file = \"46.txt\"\n",
    "character_count = calculate_total_character_count(dataset_file)\n",
    "print(\"Sum of total number of characters:\", character_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12dd033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words present in data set: 1106\n"
     ]
    }
   ],
   "source": [
    "def count_positive_words(main_dataset_file, positive_words_file):\n",
    "    \n",
    "    with open(main_dataset_file, 'r', encoding='utf-8') as main_file:\n",
    "        main_data = main_file.read()\n",
    "\n",
    "   \n",
    "    with open(positive_words_file, 'r', encoding='utf-8') as positive_file:\n",
    "        positive_words = positive_file.read().splitlines()\n",
    "\n",
    "    \n",
    "    words = main_data.split()\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "   \n",
    "    for word in words:\n",
    "      \n",
    "        if word in positive_words:\n",
    "            count += 1\n",
    "\n",
    "    \n",
    "    print(\"Total stop words present in data set:\", count)\n",
    "\n",
    "\n",
    "main_dataset_file = '46.txt'\n",
    "positive_words_file = 'all-stop-words.txt'\n",
    "\n",
    "\n",
    "count_positive_words(main_dataset_file, positive_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "531a43cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the dataset file: 3512\n"
     ]
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    exceptions = ['es', 'ed']\n",
    "    count = 0\n",
    "    prev_char_vowel = False\n",
    "\n",
    "    if word[-2:] in exceptions:\n",
    "        return count\n",
    "\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            if not prev_char_vowel:\n",
    "                count += 1\n",
    "            prev_char_vowel = True\n",
    "        else:\n",
    "            prev_char_vowel = False\n",
    "\n",
    "    return count\n",
    "\n",
    "def sum_syllables_in_file(file):\n",
    "    total_syllables = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = data.split()\n",
    "\n",
    "        for word in words:\n",
    "            total_syllables += count_syllables(word)\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "dataset_file = \"46.txt\"\n",
    "total_syllables = sum_syllables_in_file(dataset_file)\n",
    "print(\"Total syllables in the dataset file:\", total_syllables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8583f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of personal pronouns mentioned: 8\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_personal_pronouns(file):\n",
    "    pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    count = 0\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        words = re.findall(r'\\b(?:{})\\b'.format('|'.join(pronouns)), data)\n",
    "\n",
    "        for word in words:\n",
    "           \n",
    "            if word.lower() != 'us':\n",
    "                count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "dataset_file = \"46.txt\"\n",
    "pronoun_count = count_personal_pronouns(dataset_file)\n",
    "print(\"Number of personal pronouns mentioned:\", pronoun_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd43f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7650a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19a766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
